


keras07_mlp1

행렬데이터를 이용한 모델 구성



keras07_mlp2

행/열 전환(전치행렬)  x= x.transpose() ,x= x.T  



keras07_mlp3

전치행렬을 이용한 모델 구성


keras07_mlp4

range 함수와 x.T, y.T를 이용한 모델 구성


keras07_mlp5

x는 3개 y는 2개  input 3개 output 2개를 이용한 모델 구성


keras07_mlp6

x는 3개 y는 3개를 이용한 모델 구성


keras07_mlp7

x는 1개 y는 3개를 이용한 모델 구성    **잘 쓰지 않는다**


keras08_train_test1

fit과 evaluate에 데이터를 나누어서 넣는법
train데이터와 test데이터를 나눈다.
x_train, y_train, x_test, y_test


keras08_train_test2

넘파이 리스트 슬라이싱을 이용한 자료 나누기
x[:7] = x의 첫번째부터 7번째까지 
x[7:] = x의 7번째 초과부터 마지막까지
x.shape<< 잘 모르겠으면 모양 항상 확인해보기


keras08_train_test3

**사이킷런** import sklearn 을 활용한 train,test 슬라이싱
train과 test를 'shuffle'해서 일정 비율로 뽑아내는 방법

import sklearn
x_train, x_test, y_train, y_test = train_test split(x, y, test_size=0.3, shuffle=True(디폴트가 True), random_state=x)
*random_state-> 랜덤 시드값. 랜덤이더라도 다음에 같은 환경에서 훈련할 수 있도록 잡아주는 시드
*test_size, train_size 어떤것으로 해도 상관 없다.

print('x_train shape:', x_train.shape) 등으로 모양을 확인하자

나누어진 x y train, test를 각각 evaluate(트레인)와 predict(테스트)에 활용한다.





keras09_scatter

맷플롯라이브러리-파이플롯을 이용한 간단한 데이터 시각화



keras10_R2

from sklearn.metrix import r2_score를 이용한 결정계수 R2 구하는법




keras11 

sklearn.datasets import load_boston, california, diabetes 를 이용한
모델 구성



keras12_verbose

verbose 함수를 이용한 fit, evaluate 아봉


keras13
dacon의 ddarung 데이터를 이용한 모델링
***결측치 제거법***
csv 입력시키는법, csv에서 x와 y 컬런을 따로 지정해 주는법
read_csv를 이용한 입력
파일명 뒤에 drop, dropna를 이용한 컬런 버리기 기법




keras14
캐글 바이크 모델링



keras15
validation에 관하여
훈련중 자체 테스트를 통해 w값을 조정한다.


keras16
overfit에 관해.
모델링을 통해 overfit을 눈으로 확인해봄



keras17
EarlyStopping 을 이용한 
최적의 w값 보존법


keras18
이진분류의 활성화 함수 sigmoid
이진분류의 로스값 산출 함수는 binary_crossentropy
최종 값은 0이나 1이어야 하므로 반올림 함수 round를 사용하여 0이나 1로 맞춰주어야 한다.



keras19
다중분류의 활성화 함수 softmax
부드러운 최대값이라는 뜻으로 각 컬런마다 확률을 부여하여 출력한다.
이 방식은 0.5 이하의 확률이 부여될 수도 있다. 때문에 round 함수는 사용하지 못하고
가장 높은 값을 출력해주는 argmax 함수를 사용하여 가장 높은 값을 출력한다.
이 방식을 사용하면 데이터는 수치가 아닌 class가 
되어야 하므로 수치로 분류하면 문제가 생긴다.
때문에 onehotencoder 를 통해 데이터를 수치가 
아닌 위치로 저장 시키는 preprocessing(전처리)과정을 거쳐 문제가 없다.


keras20
argmax의 계산법에 관하여.
axis=0은 행끼리 비교, axis=1은 열끼리 비교 시킨다.


keras21
onehot인코더에 관해 조사했다


keras22
summary 함수에 관하여.
서머리 함수는 모델의 각 노드 파라미터의 합을 보여준다.
이 때에는 각 노드마다 bias를 합치는 작업도 하기때문에 각 계산횟수+노드의 갯수가 된다.


keras23
scaler에 관하여
데이터가 커지면 커질수록 컴퓨터 메모리에 부담이 가고, 실제로 너무 커지면 시스템이 다운된다.
때문에 데이터를 비율대로 줄여줄 필요가 있는데 이것이 scaler.
단순히 크기만 줄여 부담을 줄이고 속도를 올리는 것 뿐만 아니라 성능 향상도 노려볼 수 있다.
자세한 내용은 23번으로
스케일러는 항상 내가 원하는 사이즈를 갖도록 fit 해준 후
변환할 데이터에 transform을 적용해야한다.
스케일러는 일반적으로 훈련 데이터에만 정규화 한다. 과적합 때문.
x_train의 스케일 비율대로 test도 스케일 해준다.


keras24
input_dim 을 써서 단순히 차원만 입력했던 지금까지와 달리
input_shape로 모양 자체로 모델에 입력하는 방법을 배움.


keras25
함수형 모델에 관해 배움
Input 레이어를 만든 후 각 레이어마다 연결해주고
아웃풋 레이어 명시, 최종적으로 모델에 대한 정의를 한다.


keras26
모델의 저장과 불러오기에 관한 내용
저장하는 위치, 불러오는 위치에 따라 적용 방식이 다르다.


keras27
ModelChekpoint에 관해 배운다.
기본 골자는 es와 비슷하나, 모델의 최적의 w값을 파일로 저장할 수 있다.


keras28
dropout 레이어에 관해 배움
모델의 훈련때 오버핏을 방지하기 위해 훈련 자체 노드수를 줄여서 훈련시키는 방법
이 방법이 항상 좋다고 할 수는 없으나 하이퍼파라미터 튜닝의 한 종류이다


keras29
LabelEncoder에 관해
범주형 데이터를 숫자로 바꾸는 방법에 관해 배움
스케일러와 같이 fit과 transform을 통해 작동시킨다.




