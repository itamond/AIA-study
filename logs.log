2023-04-29 11:28:31,728:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 11:28:31,728:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 11:28:31,728:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 11:28:31,728:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 11:28:32,242:INFO:Soft dependency imported: prophet: 1.1.2
2023-04-29 11:47:02,622:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 11:47:02,622:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 11:47:02,622:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 11:47:02,622:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 11:47:02,978:INFO:Soft dependency imported: prophet: 1.1.2
2023-04-29 11:47:28,356:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 11:47:28,356:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 11:47:28,356:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 11:47:28,356:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 11:47:28,709:INFO:Soft dependency imported: prophet: 1.1.2
2023-04-29 11:47:36,262:INFO:PyCaret ClassificationExperiment
2023-04-29 11:47:36,262:INFO:Logging name: clf-default-name
2023-04-29 11:47:36,262:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-29 11:47:36,262:INFO:version 3.0.0
2023-04-29 11:47:36,262:INFO:Initializing setup()
2023-04-29 11:47:36,262:INFO:self.USI: 4c38
2023-04-29 11:47:36,262:INFO:self._variable_keys: {'log_plots_param', 'is_multiclass', 'y', 'fold_shuffle_param', 'pipeline', 'idx', 'target_param', 'USI', 'X_test', 'gpu_n_jobs_param', 'fix_imbalance', 'data', '_available_plots', 'fold_groups_param', 'seed', '_ml_usecase', 'y_test', 'exp_id', 'n_jobs_param', 'html_param', 'y_train', 'X_train', 'exp_name_log', 'X', 'memory', 'gpu_param', 'fold_generator', 'logging_param'}
2023-04-29 11:47:36,262:INFO:Checking environment
2023-04-29 11:47:36,262:INFO:python_version: 3.9.12
2023-04-29 11:47:36,262:INFO:python_build: ('main', 'Apr  4 2022 05:22:27')
2023-04-29 11:47:36,262:INFO:machine: AMD64
2023-04-29 11:47:36,270:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-29 11:47:36,272:INFO:Memory: svmem(total=67772514304, available=58418946048, percent=13.8, used=9353568256, free=58418946048)
2023-04-29 11:47:36,272:INFO:Physical Core: 8
2023-04-29 11:47:36,272:INFO:Logical Core: 16
2023-04-29 11:47:36,272:INFO:Checking libraries
2023-04-29 11:47:36,272:INFO:System:
2023-04-29 11:47:36,272:INFO:    python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]
2023-04-29 11:47:36,272:INFO:executable: C:\Users\Administrator\anaconda3\envs\tf274gpu\python.exe
2023-04-29 11:47:36,272:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-29 11:47:36,272:INFO:PyCaret required dependencies:
2023-04-29 11:47:36,272:INFO:                 pip: 21.2.4
2023-04-29 11:47:36,272:INFO:          setuptools: 61.2.0
2023-04-29 11:47:36,272:INFO:             pycaret: 3.0.0
2023-04-29 11:47:36,272:INFO:             IPython: 7.34.0
2023-04-29 11:47:36,272:INFO:          ipywidgets: 7.6.5
2023-04-29 11:47:36,272:INFO:                tqdm: 4.64.0
2023-04-29 11:47:36,272:INFO:               numpy: 1.21.6
2023-04-29 11:47:36,272:INFO:              pandas: 1.5.3
2023-04-29 11:47:36,272:INFO:              jinja2: 3.1.2
2023-04-29 11:47:36,272:INFO:               scipy: 1.9.1
2023-04-29 11:47:36,272:INFO:              joblib: 1.2.0
2023-04-29 11:47:36,272:INFO:             sklearn: 1.2.2
2023-04-29 11:47:36,272:INFO:                pyod: 1.0.9
2023-04-29 11:47:36,272:INFO:            imblearn: 0.10.1
2023-04-29 11:47:36,272:INFO:   category_encoders: 2.6.0
2023-04-29 11:47:36,272:INFO:            lightgbm: 3.3.5
2023-04-29 11:47:36,272:INFO:               numba: 0.55.1
2023-04-29 11:47:36,272:INFO:            requests: 2.27.1
2023-04-29 11:47:36,272:INFO:          matplotlib: 3.5.1
2023-04-29 11:47:36,272:INFO:          scikitplot: 0.3.7
2023-04-29 11:47:36,272:INFO:         yellowbrick: 1.5
2023-04-29 11:47:36,272:INFO:              plotly: 5.14.1
2023-04-29 11:47:36,272:INFO:             kaleido: 0.2.1
2023-04-29 11:47:36,272:INFO:         statsmodels: 0.13.2
2023-04-29 11:47:36,272:INFO:              sktime: 0.17.2
2023-04-29 11:47:36,272:INFO:               tbats: 1.1.3
2023-04-29 11:47:36,272:INFO:            pmdarima: 2.0.3
2023-04-29 11:47:36,272:INFO:              psutil: 5.9.5
2023-04-29 11:47:36,272:INFO:PyCaret optional dependencies:
2023-04-29 11:47:36,277:INFO:                shap: Not installed
2023-04-29 11:47:36,277:INFO:           interpret: Not installed
2023-04-29 11:47:36,277:INFO:                umap: Not installed
2023-04-29 11:47:36,277:INFO:    pandas_profiling: Not installed
2023-04-29 11:47:36,277:INFO:  explainerdashboard: Not installed
2023-04-29 11:47:36,277:INFO:             autoviz: Not installed
2023-04-29 11:47:36,277:INFO:           fairlearn: Not installed
2023-04-29 11:47:36,277:INFO:             xgboost: 1.7.5
2023-04-29 11:47:36,277:INFO:            catboost: 1.1.1
2023-04-29 11:47:36,277:INFO:              kmodes: Not installed
2023-04-29 11:47:36,277:INFO:             mlxtend: Not installed
2023-04-29 11:47:36,277:INFO:       statsforecast: Not installed
2023-04-29 11:47:36,277:INFO:        tune_sklearn: Not installed
2023-04-29 11:47:36,277:INFO:                 ray: Not installed
2023-04-29 11:47:36,277:INFO:            hyperopt: Not installed
2023-04-29 11:47:36,277:INFO:              optuna: 3.1.1
2023-04-29 11:47:36,277:INFO:               skopt: Not installed
2023-04-29 11:47:36,277:INFO:              mlflow: Not installed
2023-04-29 11:47:36,277:INFO:              gradio: Not installed
2023-04-29 11:47:36,277:INFO:             fastapi: Not installed
2023-04-29 11:47:36,277:INFO:             uvicorn: Not installed
2023-04-29 11:47:36,277:INFO:              m2cgen: Not installed
2023-04-29 11:47:36,277:INFO:           evidently: Not installed
2023-04-29 11:47:36,277:INFO:               fugue: Not installed
2023-04-29 11:47:36,277:INFO:           streamlit: Not installed
2023-04-29 11:47:36,277:INFO:             prophet: 1.1.2
2023-04-29 11:47:36,277:INFO:None
2023-04-29 11:47:36,277:INFO:Set up data.
2023-04-29 11:48:42,019:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 11:48:42,019:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 11:48:42,019:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 11:48:42,019:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 11:48:42,376:INFO:Soft dependency imported: prophet: 1.1.2
2023-04-29 11:48:49,890:INFO:PyCaret ClassificationExperiment
2023-04-29 11:48:49,891:INFO:Logging name: clf-default-name
2023-04-29 11:48:49,891:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-29 11:48:49,891:INFO:version 3.0.0
2023-04-29 11:48:49,891:INFO:Initializing setup()
2023-04-29 11:48:49,891:INFO:self.USI: 002e
2023-04-29 11:48:49,891:INFO:self._variable_keys: {'X_train', 'y_train', 'fix_imbalance', 'n_jobs_param', 'target_param', 'exp_id', 'X', 'X_test', 'seed', 'USI', 'pipeline', 'y', 'html_param', 'gpu_n_jobs_param', 'memory', 'data', 'exp_name_log', 'fold_groups_param', 'idx', 'is_multiclass', 'gpu_param', '_available_plots', '_ml_usecase', 'logging_param', 'fold_shuffle_param', 'y_test', 'log_plots_param', 'fold_generator'}
2023-04-29 11:48:49,891:INFO:Checking environment
2023-04-29 11:48:49,891:INFO:python_version: 3.9.12
2023-04-29 11:48:49,891:INFO:python_build: ('main', 'Apr  4 2022 05:22:27')
2023-04-29 11:48:49,891:INFO:machine: AMD64
2023-04-29 11:48:49,898:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-29 11:48:49,901:INFO:Memory: svmem(total=67772514304, available=58384703488, percent=13.9, used=9387810816, free=58384703488)
2023-04-29 11:48:49,901:INFO:Physical Core: 8
2023-04-29 11:48:49,901:INFO:Logical Core: 16
2023-04-29 11:48:49,901:INFO:Checking libraries
2023-04-29 11:48:49,901:INFO:System:
2023-04-29 11:48:49,901:INFO:    python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]
2023-04-29 11:48:49,901:INFO:executable: C:\Users\Administrator\anaconda3\envs\tf274gpu\python.exe
2023-04-29 11:48:49,901:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-29 11:48:49,901:INFO:PyCaret required dependencies:
2023-04-29 11:48:49,901:INFO:                 pip: 21.2.4
2023-04-29 11:48:49,901:INFO:          setuptools: 61.2.0
2023-04-29 11:48:49,901:INFO:             pycaret: 3.0.0
2023-04-29 11:48:49,901:INFO:             IPython: 7.34.0
2023-04-29 11:48:49,901:INFO:          ipywidgets: 7.6.5
2023-04-29 11:48:49,901:INFO:                tqdm: 4.64.0
2023-04-29 11:48:49,901:INFO:               numpy: 1.21.6
2023-04-29 11:48:49,901:INFO:              pandas: 1.5.3
2023-04-29 11:48:49,901:INFO:              jinja2: 3.1.2
2023-04-29 11:48:49,901:INFO:               scipy: 1.9.1
2023-04-29 11:48:49,901:INFO:              joblib: 1.2.0
2023-04-29 11:48:49,901:INFO:             sklearn: 1.2.2
2023-04-29 11:48:49,901:INFO:                pyod: 1.0.9
2023-04-29 11:48:49,901:INFO:            imblearn: 0.10.1
2023-04-29 11:48:49,901:INFO:   category_encoders: 2.6.0
2023-04-29 11:48:49,901:INFO:            lightgbm: 3.3.5
2023-04-29 11:48:49,901:INFO:               numba: 0.55.1
2023-04-29 11:48:49,901:INFO:            requests: 2.27.1
2023-04-29 11:48:49,901:INFO:          matplotlib: 3.5.1
2023-04-29 11:48:49,901:INFO:          scikitplot: 0.3.7
2023-04-29 11:48:49,901:INFO:         yellowbrick: 1.5
2023-04-29 11:48:49,901:INFO:              plotly: 5.14.1
2023-04-29 11:48:49,901:INFO:             kaleido: 0.2.1
2023-04-29 11:48:49,901:INFO:         statsmodels: 0.13.2
2023-04-29 11:48:49,901:INFO:              sktime: 0.17.2
2023-04-29 11:48:49,901:INFO:               tbats: 1.1.3
2023-04-29 11:48:49,901:INFO:            pmdarima: 2.0.3
2023-04-29 11:48:49,901:INFO:              psutil: 5.9.5
2023-04-29 11:48:49,901:INFO:PyCaret optional dependencies:
2023-04-29 11:48:49,906:INFO:                shap: Not installed
2023-04-29 11:48:49,906:INFO:           interpret: Not installed
2023-04-29 11:48:49,906:INFO:                umap: Not installed
2023-04-29 11:48:49,906:INFO:    pandas_profiling: Not installed
2023-04-29 11:48:49,906:INFO:  explainerdashboard: Not installed
2023-04-29 11:48:49,906:INFO:             autoviz: Not installed
2023-04-29 11:48:49,906:INFO:           fairlearn: Not installed
2023-04-29 11:48:49,906:INFO:             xgboost: 1.7.5
2023-04-29 11:48:49,906:INFO:            catboost: 1.1.1
2023-04-29 11:48:49,906:INFO:              kmodes: Not installed
2023-04-29 11:48:49,906:INFO:             mlxtend: Not installed
2023-04-29 11:48:49,906:INFO:       statsforecast: Not installed
2023-04-29 11:48:49,906:INFO:        tune_sklearn: Not installed
2023-04-29 11:48:49,906:INFO:                 ray: Not installed
2023-04-29 11:48:49,906:INFO:            hyperopt: Not installed
2023-04-29 11:48:49,906:INFO:              optuna: 3.1.1
2023-04-29 11:48:49,906:INFO:               skopt: Not installed
2023-04-29 11:48:49,906:INFO:              mlflow: Not installed
2023-04-29 11:48:49,906:INFO:              gradio: Not installed
2023-04-29 11:48:49,906:INFO:             fastapi: Not installed
2023-04-29 11:48:49,906:INFO:             uvicorn: Not installed
2023-04-29 11:48:49,906:INFO:              m2cgen: Not installed
2023-04-29 11:48:49,906:INFO:           evidently: Not installed
2023-04-29 11:48:49,906:INFO:               fugue: Not installed
2023-04-29 11:48:49,906:INFO:           streamlit: Not installed
2023-04-29 11:48:49,906:INFO:             prophet: 1.1.2
2023-04-29 11:48:49,906:INFO:None
2023-04-29 11:48:49,906:INFO:Set up data.
2023-04-29 11:48:49,985:INFO:Set up train/test split.
2023-04-29 11:48:50,111:INFO:Set up index.
2023-04-29 11:48:50,112:INFO:Set up folding strategy.
2023-04-29 11:48:50,112:INFO:Assigning column types.
2023-04-29 11:48:50,132:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 11:48:50,155:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 11:48:50,156:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 11:48:50,174:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 11:48:50,205:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 11:48:50,288:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 11:48:50,289:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 11:48:50,304:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 11:48:50,306:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 11:48:50,306:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 11:48:50,331:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 11:48:50,347:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 11:48:50,348:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 11:48:50,373:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 11:48:50,389:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 11:48:50,390:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 11:48:50,390:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-29 11:48:50,430:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 11:48:50,432:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 11:48:50,472:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 11:48:50,474:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 11:48:50,476:INFO:Preparing preprocessing pipeline...
2023-04-29 11:48:50,480:INFO:Set up label encoding.
2023-04-29 11:48:50,480:INFO:Set up simple imputation.
2023-04-29 11:48:50,482:INFO:Set up column name cleaning.
2023-04-29 11:48:51,815:INFO:Finished creating preprocessing pipeline.
2023-04-29 11:48:51,818:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Month', 'Day_of_Month',
                                             'Estimated_Departure_Time',
                                             'Estimated_Arrival_Time',
                                             'Cancelled', 'Diverted'...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-04-29 11:48:51,818:INFO:Creating final display dataframe.
2023-04-29 11:48:53,672:INFO:Setup _display_container:                     Description                       Value
0                    Session id                        8245
1                        Target                       Delay
2                   Target type                      Binary
3                Target mapping  Delayed: 0, Not_Delayed: 1
4           Original data shape                (255001, 18)
5        Transformed data shape                (255001, 18)
6   Transformed train set shape                (204000, 18)
7    Transformed test set shape                 (51001, 18)
8              Numeric features                          17
9                    Preprocess                        True
10              Imputation type                      simple
11           Numeric imputation                        mean
12       Categorical imputation                        mode
13               Fold Generator             StratifiedKFold
14                  Fold Number                          10
15                     CPU Jobs                          -1
16                      Use GPU                       False
17               Log Experiment                       False
18              Experiment Name            clf-default-name
19                          USI                        002e
2023-04-29 11:48:53,715:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 11:48:53,716:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 11:48:53,756:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 11:48:53,758:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 11:48:53,758:INFO:setup() successfully completed in 3.87s...............
2023-04-29 11:48:53,759:INFO:Initializing compare_models()
2023-04-29 11:48:53,759:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>, include=None, fold=5, round=4, cross_validation=True, sort=f1_score, n_select=2, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>, 'include': None, 'exclude': ['svm', 'ridge'], 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'f1_score', 'n_select': 2, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['svm', 'ridge'])
2023-04-29 11:48:53,759:INFO:Checking exceptions
2023-04-29 11:48:53,808:INFO:Preparing display monitor
2023-04-29 11:48:53,810:INFO:Initializing Logistic Regression
2023-04-29 11:48:53,810:INFO:Total runtime is 0.0 minutes
2023-04-29 11:48:53,810:INFO:SubProcess create_model() called ==================================
2023-04-29 11:48:53,810:INFO:Initializing create_model()
2023-04-29 11:48:53,810:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D65B1BA90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 11:48:53,810:INFO:Checking exceptions
2023-04-29 11:48:53,810:INFO:Importing libraries
2023-04-29 11:48:53,810:INFO:Copying training dataset
2023-04-29 11:48:53,880:INFO:Defining folds
2023-04-29 11:48:53,880:INFO:Declaring metric variables
2023-04-29 11:48:53,880:INFO:Importing untrained model
2023-04-29 11:48:53,880:INFO:Logistic Regression Imported successfully
2023-04-29 11:48:53,880:INFO:Starting cross validation
2023-04-29 11:48:53,881:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 11:48:59,165:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:48:59,182:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:48:59,475:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:48:59,491:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:48:59,579:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:48:59,595:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:48:59,737:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:48:59,754:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:49:00,005:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:49:00,025:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:49:00,351:INFO:Calculating mean and std
2023-04-29 11:49:00,352:INFO:Creating metrics dataframe
2023-04-29 11:49:00,356:INFO:Uploading results into container
2023-04-29 11:49:00,356:INFO:Uploading model into container now
2023-04-29 11:49:00,356:INFO:_master_model_container: 1
2023-04-29 11:49:00,356:INFO:_display_container: 2
2023-04-29 11:49:00,356:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-29 11:49:00,356:INFO:create_model() successfully completed......................................
2023-04-29 11:49:00,407:INFO:SubProcess create_model() end ==================================
2023-04-29 11:49:00,407:INFO:Creating metrics dataframe
2023-04-29 11:49:00,409:INFO:Initializing K Neighbors Classifier
2023-04-29 11:49:00,409:INFO:Total runtime is 0.10997494061787923 minutes
2023-04-29 11:49:00,409:INFO:SubProcess create_model() called ==================================
2023-04-29 11:49:00,409:INFO:Initializing create_model()
2023-04-29 11:49:00,409:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D65B1BA90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 11:49:00,409:INFO:Checking exceptions
2023-04-29 11:49:00,409:INFO:Importing libraries
2023-04-29 11:49:00,409:INFO:Copying training dataset
2023-04-29 11:49:00,493:INFO:Defining folds
2023-04-29 11:49:00,493:INFO:Declaring metric variables
2023-04-29 11:49:00,493:INFO:Importing untrained model
2023-04-29 11:49:00,493:INFO:K Neighbors Classifier Imported successfully
2023-04-29 11:49:00,495:INFO:Starting cross validation
2023-04-29 11:49:00,495:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 11:49:39,069:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:49:39,085:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:49:39,113:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:49:39,129:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:49:39,155:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:49:39,172:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:49:39,257:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:49:39,272:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:49:39,514:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:49:39,530:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:49:39,757:INFO:Calculating mean and std
2023-04-29 11:49:39,757:INFO:Creating metrics dataframe
2023-04-29 11:49:39,761:INFO:Uploading results into container
2023-04-29 11:49:39,761:INFO:Uploading model into container now
2023-04-29 11:49:39,761:INFO:_master_model_container: 2
2023-04-29 11:49:39,761:INFO:_display_container: 2
2023-04-29 11:49:39,762:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-29 11:49:39,762:INFO:create_model() successfully completed......................................
2023-04-29 11:49:39,820:INFO:SubProcess create_model() end ==================================
2023-04-29 11:49:39,820:INFO:Creating metrics dataframe
2023-04-29 11:49:39,823:INFO:Initializing Naive Bayes
2023-04-29 11:49:39,823:INFO:Total runtime is 0.7668806473414104 minutes
2023-04-29 11:49:39,823:INFO:SubProcess create_model() called ==================================
2023-04-29 11:49:39,823:INFO:Initializing create_model()
2023-04-29 11:49:39,823:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D65B1BA90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 11:49:39,823:INFO:Checking exceptions
2023-04-29 11:49:39,823:INFO:Importing libraries
2023-04-29 11:49:39,823:INFO:Copying training dataset
2023-04-29 11:49:39,903:INFO:Defining folds
2023-04-29 11:49:39,903:INFO:Declaring metric variables
2023-04-29 11:49:39,903:INFO:Importing untrained model
2023-04-29 11:49:39,903:INFO:Naive Bayes Imported successfully
2023-04-29 11:49:39,903:INFO:Starting cross validation
2023-04-29 11:49:39,904:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 11:49:43,431:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:49:43,447:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:49:43,448:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:49:43,464:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:49:43,534:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:49:43,550:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:49:43,629:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:49:43,644:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:49:43,699:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:49:43,715:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:49:43,943:INFO:Calculating mean and std
2023-04-29 11:49:43,944:INFO:Creating metrics dataframe
2023-04-29 11:49:43,947:INFO:Uploading results into container
2023-04-29 11:49:43,947:INFO:Uploading model into container now
2023-04-29 11:49:43,947:INFO:_master_model_container: 3
2023-04-29 11:49:43,948:INFO:_display_container: 2
2023-04-29 11:49:43,948:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-29 11:49:43,948:INFO:create_model() successfully completed......................................
2023-04-29 11:49:44,000:INFO:SubProcess create_model() end ==================================
2023-04-29 11:49:44,001:INFO:Creating metrics dataframe
2023-04-29 11:49:44,003:INFO:Initializing Decision Tree Classifier
2023-04-29 11:49:44,003:INFO:Total runtime is 0.8365415732065837 minutes
2023-04-29 11:49:44,003:INFO:SubProcess create_model() called ==================================
2023-04-29 11:49:44,004:INFO:Initializing create_model()
2023-04-29 11:49:44,004:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D65B1BA90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 11:49:44,004:INFO:Checking exceptions
2023-04-29 11:49:44,004:INFO:Importing libraries
2023-04-29 11:49:44,004:INFO:Copying training dataset
2023-04-29 11:49:44,082:INFO:Defining folds
2023-04-29 11:49:44,082:INFO:Declaring metric variables
2023-04-29 11:49:44,082:INFO:Importing untrained model
2023-04-29 11:49:44,082:INFO:Decision Tree Classifier Imported successfully
2023-04-29 11:49:44,082:INFO:Starting cross validation
2023-04-29 11:49:44,083:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 11:49:47,827:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 5, in union1d
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 777, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 5, in unique
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 272, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 333, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'float' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=['Delayed' 'Not_Delayed'] and y_pred=[0. 1.]. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2023-04-29 11:49:47,855:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 5, in union1d
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 777, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 5, in unique
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 272, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 333, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'float' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=['Delayed' 'Not_Delayed'] and y_pred=[0. 1.]. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2023-04-29 11:49:47,895:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 5, in union1d
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 777, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 5, in unique
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 272, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 333, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'float' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=['Delayed' 'Not_Delayed'] and y_pred=[0. 1.]. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2023-04-29 11:49:47,923:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 5, in union1d
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 777, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 5, in unique
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 272, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 333, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'float' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=['Delayed' 'Not_Delayed'] and y_pred=[0. 1.]. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2023-04-29 11:49:48,061:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 5, in union1d
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 777, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 5, in unique
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 272, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 333, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'float' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=['Delayed' 'Not_Delayed'] and y_pred=[0. 1.]. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2023-04-29 11:49:48,088:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 5, in union1d
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 777, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 5, in unique
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 272, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 333, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'float' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=['Delayed' 'Not_Delayed'] and y_pred=[0. 1.]. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2023-04-29 11:49:48,144:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 5, in union1d
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 777, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 5, in unique
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 272, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 333, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'float' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=['Delayed' 'Not_Delayed'] and y_pred=[0. 1.]. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2023-04-29 11:49:48,173:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 5, in union1d
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 777, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 5, in unique
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 272, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 333, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'float' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=['Delayed' 'Not_Delayed'] and y_pred=[0. 1.]. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2023-04-29 11:49:48,994:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 5, in union1d
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 777, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 5, in unique
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 272, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 333, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'float' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=['Delayed' 'Not_Delayed'] and y_pred=[0. 1.]. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2023-04-29 11:49:49,023:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 5, in union1d
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 777, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 5, in unique
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 272, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 333, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'float' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=['Delayed' 'Not_Delayed'] and y_pred=[0. 1.]. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2023-04-29 11:49:49,352:INFO:Calculating mean and std
2023-04-29 11:49:49,352:INFO:Creating metrics dataframe
2023-04-29 11:49:49,356:INFO:Uploading results into container
2023-04-29 11:49:49,356:INFO:Uploading model into container now
2023-04-29 11:49:49,357:INFO:_master_model_container: 4
2023-04-29 11:49:49,357:INFO:_display_container: 2
2023-04-29 11:49:49,357:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8245, splitter='best')
2023-04-29 11:49:49,357:INFO:create_model() successfully completed......................................
2023-04-29 11:49:49,409:INFO:SubProcess create_model() end ==================================
2023-04-29 11:49:49,409:INFO:Creating metrics dataframe
2023-04-29 11:49:49,411:INFO:Initializing Random Forest Classifier
2023-04-29 11:49:49,411:INFO:Total runtime is 0.9266849875450135 minutes
2023-04-29 11:49:49,411:INFO:SubProcess create_model() called ==================================
2023-04-29 11:49:49,411:INFO:Initializing create_model()
2023-04-29 11:49:49,411:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D65B1BA90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 11:49:49,411:INFO:Checking exceptions
2023-04-29 11:49:49,411:INFO:Importing libraries
2023-04-29 11:49:49,411:INFO:Copying training dataset
2023-04-29 11:49:49,490:INFO:Defining folds
2023-04-29 11:49:49,490:INFO:Declaring metric variables
2023-04-29 11:49:49,490:INFO:Importing untrained model
2023-04-29 11:49:49,490:INFO:Random Forest Classifier Imported successfully
2023-04-29 11:49:49,490:INFO:Starting cross validation
2023-04-29 11:49:49,491:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 11:50:00,817:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-29 11:50:01,690:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-29 11:50:01,862:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-29 11:50:02,637:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-29 11:50:02,684:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-29 11:50:04,219:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:04,235:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:04,281:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:04,296:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:04,305:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:04,320:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:04,705:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:04,719:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:04,746:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:04,761:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:05,084:INFO:Calculating mean and std
2023-04-29 11:50:05,084:INFO:Creating metrics dataframe
2023-04-29 11:50:05,090:INFO:Uploading results into container
2023-04-29 11:50:05,090:INFO:Uploading model into container now
2023-04-29 11:50:05,090:INFO:_master_model_container: 5
2023-04-29 11:50:05,090:INFO:_display_container: 2
2023-04-29 11:50:05,090:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8245, verbose=0, warm_start=False)
2023-04-29 11:50:05,090:INFO:create_model() successfully completed......................................
2023-04-29 11:50:05,146:INFO:SubProcess create_model() end ==================================
2023-04-29 11:50:05,146:INFO:Creating metrics dataframe
2023-04-29 11:50:05,148:INFO:Initializing Quadratic Discriminant Analysis
2023-04-29 11:50:05,148:INFO:Total runtime is 1.1889561812082927 minutes
2023-04-29 11:50:05,149:INFO:SubProcess create_model() called ==================================
2023-04-29 11:50:05,149:INFO:Initializing create_model()
2023-04-29 11:50:05,149:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D65B1BA90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 11:50:05,149:INFO:Checking exceptions
2023-04-29 11:50:05,149:INFO:Importing libraries
2023-04-29 11:50:05,149:INFO:Copying training dataset
2023-04-29 11:50:05,227:INFO:Defining folds
2023-04-29 11:50:05,228:INFO:Declaring metric variables
2023-04-29 11:50:05,228:INFO:Importing untrained model
2023-04-29 11:50:05,228:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-29 11:50:05,228:INFO:Starting cross validation
2023-04-29 11:50:05,228:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 11:50:06,549:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 11:50:06,642:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 11:50:06,747:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 11:50:06,916:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 11:50:07,060:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 11:50:07,351:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:07,366:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:07,461:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:07,477:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:07,570:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:07,585:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:07,731:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:07,747:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:07,838:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:07,858:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:08,083:INFO:Calculating mean and std
2023-04-29 11:50:08,083:INFO:Creating metrics dataframe
2023-04-29 11:50:08,089:INFO:Uploading results into container
2023-04-29 11:50:08,089:INFO:Uploading model into container now
2023-04-29 11:50:08,089:INFO:_master_model_container: 6
2023-04-29 11:50:08,089:INFO:_display_container: 2
2023-04-29 11:50:08,089:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-29 11:50:08,089:INFO:create_model() successfully completed......................................
2023-04-29 11:50:08,140:INFO:SubProcess create_model() end ==================================
2023-04-29 11:50:08,140:INFO:Creating metrics dataframe
2023-04-29 11:50:08,143:INFO:Initializing Ada Boost Classifier
2023-04-29 11:50:08,143:INFO:Total runtime is 1.2388737082481385 minutes
2023-04-29 11:50:08,143:INFO:SubProcess create_model() called ==================================
2023-04-29 11:50:08,143:INFO:Initializing create_model()
2023-04-29 11:50:08,143:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D65B1BA90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 11:50:08,143:INFO:Checking exceptions
2023-04-29 11:50:08,143:INFO:Importing libraries
2023-04-29 11:50:08,143:INFO:Copying training dataset
2023-04-29 11:50:08,222:INFO:Defining folds
2023-04-29 11:50:08,222:INFO:Declaring metric variables
2023-04-29 11:50:08,222:INFO:Importing untrained model
2023-04-29 11:50:08,222:INFO:Ada Boost Classifier Imported successfully
2023-04-29 11:50:08,223:INFO:Starting cross validation
2023-04-29 11:50:08,223:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 11:50:15,859:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:15,874:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:16,038:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:16,053:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:16,153:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:16,168:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:16,323:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:16,339:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:16,399:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:16,414:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:16,743:INFO:Calculating mean and std
2023-04-29 11:50:16,743:INFO:Creating metrics dataframe
2023-04-29 11:50:16,750:INFO:Uploading results into container
2023-04-29 11:50:16,750:INFO:Uploading model into container now
2023-04-29 11:50:16,750:INFO:_master_model_container: 7
2023-04-29 11:50:16,750:INFO:_display_container: 2
2023-04-29 11:50:16,750:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=8245)
2023-04-29 11:50:16,750:INFO:create_model() successfully completed......................................
2023-04-29 11:50:16,805:INFO:SubProcess create_model() end ==================================
2023-04-29 11:50:16,806:INFO:Creating metrics dataframe
2023-04-29 11:50:16,808:INFO:Initializing Gradient Boosting Classifier
2023-04-29 11:50:16,808:INFO:Total runtime is 1.3832974632581077 minutes
2023-04-29 11:50:16,808:INFO:SubProcess create_model() called ==================================
2023-04-29 11:50:16,808:INFO:Initializing create_model()
2023-04-29 11:50:16,808:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D65B1BA90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 11:50:16,808:INFO:Checking exceptions
2023-04-29 11:50:16,808:INFO:Importing libraries
2023-04-29 11:50:16,808:INFO:Copying training dataset
2023-04-29 11:50:16,884:INFO:Defining folds
2023-04-29 11:50:16,884:INFO:Declaring metric variables
2023-04-29 11:50:16,884:INFO:Importing untrained model
2023-04-29 11:50:16,884:INFO:Gradient Boosting Classifier Imported successfully
2023-04-29 11:50:16,885:INFO:Starting cross validation
2023-04-29 11:50:16,885:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 11:50:42,259:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:42,275:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:42,376:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:42,380:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:42,391:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:42,395:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:42,531:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:42,546:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:42,695:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:42,711:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:42,935:INFO:Calculating mean and std
2023-04-29 11:50:42,935:INFO:Creating metrics dataframe
2023-04-29 11:50:42,942:INFO:Uploading results into container
2023-04-29 11:50:42,942:INFO:Uploading model into container now
2023-04-29 11:50:42,942:INFO:_master_model_container: 8
2023-04-29 11:50:42,942:INFO:_display_container: 2
2023-04-29 11:50:42,943:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8245, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-29 11:50:42,943:INFO:create_model() successfully completed......................................
2023-04-29 11:50:43,014:INFO:SubProcess create_model() end ==================================
2023-04-29 11:50:43,014:INFO:Creating metrics dataframe
2023-04-29 11:50:43,017:INFO:Initializing Linear Discriminant Analysis
2023-04-29 11:50:43,017:INFO:Total runtime is 1.8201102415720622 minutes
2023-04-29 11:50:43,017:INFO:SubProcess create_model() called ==================================
2023-04-29 11:50:43,017:INFO:Initializing create_model()
2023-04-29 11:50:43,017:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D65B1BA90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 11:50:43,017:INFO:Checking exceptions
2023-04-29 11:50:43,017:INFO:Importing libraries
2023-04-29 11:50:43,017:INFO:Copying training dataset
2023-04-29 11:50:43,095:INFO:Defining folds
2023-04-29 11:50:43,095:INFO:Declaring metric variables
2023-04-29 11:50:43,095:INFO:Importing untrained model
2023-04-29 11:50:43,095:INFO:Linear Discriminant Analysis Imported successfully
2023-04-29 11:50:43,095:INFO:Starting cross validation
2023-04-29 11:50:43,096:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 11:50:45,503:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:45,510:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:45,518:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:45,527:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:45,652:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:45,668:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:45,782:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:45,798:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:45,927:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:45,944:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:46,166:INFO:Calculating mean and std
2023-04-29 11:50:46,167:INFO:Creating metrics dataframe
2023-04-29 11:50:46,175:INFO:Uploading results into container
2023-04-29 11:50:46,175:INFO:Uploading model into container now
2023-04-29 11:50:46,176:INFO:_master_model_container: 9
2023-04-29 11:50:46,176:INFO:_display_container: 2
2023-04-29 11:50:46,176:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-29 11:50:46,176:INFO:create_model() successfully completed......................................
2023-04-29 11:50:46,226:INFO:SubProcess create_model() end ==================================
2023-04-29 11:50:46,226:INFO:Creating metrics dataframe
2023-04-29 11:50:46,228:INFO:Initializing Extra Trees Classifier
2023-04-29 11:50:46,228:INFO:Total runtime is 1.8736268281936646 minutes
2023-04-29 11:50:46,228:INFO:SubProcess create_model() called ==================================
2023-04-29 11:50:46,228:INFO:Initializing create_model()
2023-04-29 11:50:46,228:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D65B1BA90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 11:50:46,228:INFO:Checking exceptions
2023-04-29 11:50:46,228:INFO:Importing libraries
2023-04-29 11:50:46,228:INFO:Copying training dataset
2023-04-29 11:50:46,306:INFO:Defining folds
2023-04-29 11:50:46,306:INFO:Declaring metric variables
2023-04-29 11:50:46,306:INFO:Importing untrained model
2023-04-29 11:50:46,306:INFO:Extra Trees Classifier Imported successfully
2023-04-29 11:50:46,306:INFO:Starting cross validation
2023-04-29 11:50:46,307:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 11:50:53,049:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-29 11:50:53,460:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-29 11:50:55,085:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:55,100:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:55,235:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:55,250:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:55,517:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:55,533:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:55,639:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:55,651:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:55,655:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:55,666:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:50:55,894:INFO:Calculating mean and std
2023-04-29 11:50:55,894:INFO:Creating metrics dataframe
2023-04-29 11:50:55,904:INFO:Uploading results into container
2023-04-29 11:50:55,904:INFO:Uploading model into container now
2023-04-29 11:50:55,904:INFO:_master_model_container: 10
2023-04-29 11:50:55,904:INFO:_display_container: 2
2023-04-29 11:50:55,904:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=8245, verbose=0, warm_start=False)
2023-04-29 11:50:55,904:INFO:create_model() successfully completed......................................
2023-04-29 11:50:55,964:INFO:SubProcess create_model() end ==================================
2023-04-29 11:50:55,965:INFO:Creating metrics dataframe
2023-04-29 11:50:55,967:INFO:Initializing Extreme Gradient Boosting
2023-04-29 11:50:55,967:INFO:Total runtime is 2.0359481533368426 minutes
2023-04-29 11:50:55,967:INFO:SubProcess create_model() called ==================================
2023-04-29 11:50:55,967:INFO:Initializing create_model()
2023-04-29 11:50:55,967:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>, estimator=xgboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D65B1BA90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 11:50:55,967:INFO:Checking exceptions
2023-04-29 11:50:55,967:INFO:Importing libraries
2023-04-29 11:50:55,967:INFO:Copying training dataset
2023-04-29 11:50:56,092:INFO:Defining folds
2023-04-29 11:50:56,092:INFO:Declaring metric variables
2023-04-29 11:50:56,092:INFO:Importing untrained model
2023-04-29 11:50:56,093:INFO:Extreme Gradient Boosting Imported successfully
2023-04-29 11:50:56,093:INFO:Starting cross validation
2023-04-29 11:50:56,093:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 11:51:07,931:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:07,946:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:08,220:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:08,235:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:08,283:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:08,299:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:08,314:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:08,329:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:08,424:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:08,439:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:08,663:INFO:Calculating mean and std
2023-04-29 11:51:08,663:INFO:Creating metrics dataframe
2023-04-29 11:51:08,673:INFO:Uploading results into container
2023-04-29 11:51:08,673:INFO:Uploading model into container now
2023-04-29 11:51:08,673:INFO:_master_model_container: 11
2023-04-29 11:51:08,673:INFO:_display_container: 2
2023-04-29 11:51:08,674:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-04-29 11:51:08,674:INFO:create_model() successfully completed......................................
2023-04-29 11:51:08,729:INFO:SubProcess create_model() end ==================================
2023-04-29 11:51:08,729:INFO:Creating metrics dataframe
2023-04-29 11:51:08,732:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 11:51:08,732:INFO:Total runtime is 2.2486938595771786 minutes
2023-04-29 11:51:08,732:INFO:SubProcess create_model() called ==================================
2023-04-29 11:51:08,732:INFO:Initializing create_model()
2023-04-29 11:51:08,732:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D65B1BA90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 11:51:08,733:INFO:Checking exceptions
2023-04-29 11:51:08,733:INFO:Importing libraries
2023-04-29 11:51:08,733:INFO:Copying training dataset
2023-04-29 11:51:08,811:INFO:Defining folds
2023-04-29 11:51:08,811:INFO:Declaring metric variables
2023-04-29 11:51:08,811:INFO:Importing untrained model
2023-04-29 11:51:08,812:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 11:51:08,812:INFO:Starting cross validation
2023-04-29 11:51:08,812:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 11:51:12,528:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:12,543:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:12,616:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:12,631:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:12,771:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:12,786:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:12,807:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:12,822:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:12,850:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:12,865:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:13,188:INFO:Calculating mean and std
2023-04-29 11:51:13,188:INFO:Creating metrics dataframe
2023-04-29 11:51:13,200:INFO:Uploading results into container
2023-04-29 11:51:13,200:INFO:Uploading model into container now
2023-04-29 11:51:13,200:INFO:_master_model_container: 12
2023-04-29 11:51:13,200:INFO:_display_container: 2
2023-04-29 11:51:13,200:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8245, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-29 11:51:13,200:INFO:create_model() successfully completed......................................
2023-04-29 11:51:13,251:INFO:SubProcess create_model() end ==================================
2023-04-29 11:51:13,251:INFO:Creating metrics dataframe
2023-04-29 11:51:13,253:INFO:Initializing CatBoost Classifier
2023-04-29 11:51:13,253:INFO:Total runtime is 2.3240536530812577 minutes
2023-04-29 11:51:13,253:INFO:SubProcess create_model() called ==================================
2023-04-29 11:51:13,253:INFO:Initializing create_model()
2023-04-29 11:51:13,253:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D65B1BA90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 11:51:13,253:INFO:Checking exceptions
2023-04-29 11:51:13,253:INFO:Importing libraries
2023-04-29 11:51:13,253:INFO:Copying training dataset
2023-04-29 11:51:13,344:INFO:Defining folds
2023-04-29 11:51:13,345:INFO:Declaring metric variables
2023-04-29 11:51:13,345:INFO:Importing untrained model
2023-04-29 11:51:13,345:INFO:CatBoost Classifier Imported successfully
2023-04-29 11:51:13,345:INFO:Starting cross validation
2023-04-29 11:51:13,345:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 11:51:36,516:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:36,532:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:36,644:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:36,659:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:36,822:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:36,838:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:36,916:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:36,932:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:36,962:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:36,977:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:37,202:INFO:Calculating mean and std
2023-04-29 11:51:37,202:INFO:Creating metrics dataframe
2023-04-29 11:51:37,214:INFO:Uploading results into container
2023-04-29 11:51:37,214:INFO:Uploading model into container now
2023-04-29 11:51:37,214:INFO:_master_model_container: 13
2023-04-29 11:51:37,214:INFO:_display_container: 2
2023-04-29 11:51:37,214:INFO:<catboost.core.CatBoostClassifier object at 0x0000022D0B31A250>
2023-04-29 11:51:37,214:INFO:create_model() successfully completed......................................
2023-04-29 11:51:37,278:INFO:SubProcess create_model() end ==================================
2023-04-29 11:51:37,278:INFO:Creating metrics dataframe
2023-04-29 11:51:37,281:INFO:Initializing Dummy Classifier
2023-04-29 11:51:37,281:INFO:Total runtime is 2.724505027135213 minutes
2023-04-29 11:51:37,281:INFO:SubProcess create_model() called ==================================
2023-04-29 11:51:37,281:INFO:Initializing create_model()
2023-04-29 11:51:37,281:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D65B1BA90>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 11:51:37,281:INFO:Checking exceptions
2023-04-29 11:51:37,281:INFO:Importing libraries
2023-04-29 11:51:37,281:INFO:Copying training dataset
2023-04-29 11:51:37,363:INFO:Defining folds
2023-04-29 11:51:37,363:INFO:Declaring metric variables
2023-04-29 11:51:37,363:INFO:Importing untrained model
2023-04-29 11:51:37,363:INFO:Dummy Classifier Imported successfully
2023-04-29 11:51:37,363:INFO:Starting cross validation
2023-04-29 11:51:37,364:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 11:51:39,447:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:39,462:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:39,494:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:39,508:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:39,644:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:39,659:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:39,745:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:39,760:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:39,896:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:39,912:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:40,138:INFO:Calculating mean and std
2023-04-29 11:51:40,138:INFO:Creating metrics dataframe
2023-04-29 11:51:40,150:INFO:Uploading results into container
2023-04-29 11:51:40,150:INFO:Uploading model into container now
2023-04-29 11:51:40,150:INFO:_master_model_container: 14
2023-04-29 11:51:40,151:INFO:_display_container: 2
2023-04-29 11:51:40,151:INFO:DummyClassifier(constant=None, random_state=8245, strategy='prior')
2023-04-29 11:51:40,151:INFO:create_model() successfully completed......................................
2023-04-29 11:51:40,203:INFO:SubProcess create_model() end ==================================
2023-04-29 11:51:40,203:INFO:Creating metrics dataframe
2023-04-29 11:51:40,206:INFO:Initializing create_model()
2023-04-29 11:51:40,207:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 11:51:40,207:INFO:Checking exceptions
2023-04-29 11:51:40,207:INFO:Importing libraries
2023-04-29 11:51:40,207:INFO:Copying training dataset
2023-04-29 11:51:40,286:INFO:Defining folds
2023-04-29 11:51:40,286:INFO:Declaring metric variables
2023-04-29 11:51:40,286:INFO:Importing untrained model
2023-04-29 11:51:40,286:INFO:Declaring custom model
2023-04-29 11:51:40,287:INFO:Logistic Regression Imported successfully
2023-04-29 11:51:40,287:INFO:Cross validation set to False
2023-04-29 11:51:40,287:INFO:Fitting Model
2023-04-29 11:51:42,331:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-29 11:51:42,331:INFO:create_model() successfully completed......................................
2023-04-29 11:51:42,386:INFO:Initializing create_model()
2023-04-29 11:51:42,386:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 11:51:42,386:INFO:Checking exceptions
2023-04-29 11:51:42,387:INFO:Importing libraries
2023-04-29 11:51:42,387:INFO:Copying training dataset
2023-04-29 11:51:42,467:INFO:Defining folds
2023-04-29 11:51:42,467:INFO:Declaring metric variables
2023-04-29 11:51:42,467:INFO:Importing untrained model
2023-04-29 11:51:42,467:INFO:Declaring custom model
2023-04-29 11:51:42,467:INFO:K Neighbors Classifier Imported successfully
2023-04-29 11:51:42,468:INFO:Cross validation set to False
2023-04-29 11:51:42,468:INFO:Fitting Model
2023-04-29 11:51:43,943:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-29 11:51:43,943:INFO:create_model() successfully completed......................................
2023-04-29 11:51:44,002:INFO:_master_model_container: 14
2023-04-29 11:51:44,002:INFO:_display_container: 2
2023-04-29 11:51:44,002:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')]
2023-04-29 11:51:44,002:INFO:compare_models() successfully completed......................................
2023-04-29 11:51:44,003:INFO:Initializing tune_model()
2023-04-29 11:51:44,003:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1_score, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>)
2023-04-29 11:51:44,003:INFO:Checking exceptions
2023-04-29 11:51:44,036:INFO:Copying training dataset
2023-04-29 11:51:44,100:INFO:Checking base model
2023-04-29 11:51:44,100:INFO:Base model : Logistic Regression
2023-04-29 11:51:44,100:INFO:Declaring metric variables
2023-04-29 11:51:44,100:INFO:Defining Hyperparameters
2023-04-29 11:51:44,153:INFO:Tuning with n_jobs=-1
2023-04-29 11:51:44,153:INFO:Initializing RandomizedSearchCV
2023-04-29 11:51:47,843:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:48,159:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:48,464:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:48,669:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:49,136:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:49,702:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:51,089:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:51,093:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:51,172:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:52,464:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:52,855:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:53,660:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:53,796:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:54,027:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:54,231:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:54,434:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:55,728:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:56,550:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:56,565:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:57,107:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:57,512:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:57,751:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:57,989:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:58,157:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:58,351:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:51:58,971:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:00,306:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:00,510:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:00,530:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-29 11:52:00,623:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:01,876:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-29 11:52:01,979:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:02,296:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:02,511:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:02,947:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:03,436:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:03,654:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:03,924:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:05,865:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:05,872:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:06,766:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:06,987:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-29 11:52:07,112:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:07,243:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:07,380:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-29 11:52:07,458:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:07,563:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:07,587:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:07,766:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:08,739:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:10,502:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:11,170:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-29 11:52:11,279:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:11,347:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-29 11:52:11,445:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:11,778:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:11,937:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:12,077:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:12,644:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:12,705:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:12,733:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:13,576:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:15,759:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-29 11:52:15,882:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:16,170:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-29 11:52:16,277:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:16,621:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-29 11:52:16,760:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:16,919:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:17,362:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:17,491:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:17,603:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:17,619:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:17,812:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:18,650:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:19,579:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:19,777:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:20,048:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:20,767:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:21,572:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:22,437:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:22,683:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:22,761:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:23,848:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:23,997:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:24,391:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:25,551:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-29 11:52:25,639:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:25,951:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:26,085:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:26,303:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:26,454:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:26,755:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:26,878:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:26,992:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:27,752:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:29,869:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:30,261:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:30,404:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:30,649:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:30,750:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:30,785:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:31,319:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:31,819:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:31,860:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:32,281:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:32,530:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:32,551:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:32,560:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:32,684:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:32,933:INFO:best_params: {'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 4.322}
2023-04-29 11:52:32,933:INFO:Hyperparameter search completed
2023-04-29 11:52:32,933:INFO:SubProcess create_model() called ==================================
2023-04-29 11:52:32,933:INFO:Initializing create_model()
2023-04-29 11:52:32,933:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D032051C0>, model_only=True, return_train_score=False, kwargs={'class_weight': 'balanced', 'C': 4.322})
2023-04-29 11:52:32,933:INFO:Checking exceptions
2023-04-29 11:52:32,933:INFO:Importing libraries
2023-04-29 11:52:32,933:INFO:Copying training dataset
2023-04-29 11:52:33,025:INFO:Defining folds
2023-04-29 11:52:33,025:INFO:Declaring metric variables
2023-04-29 11:52:33,026:INFO:Importing untrained model
2023-04-29 11:52:33,026:INFO:Declaring custom model
2023-04-29 11:52:33,026:INFO:Logistic Regression Imported successfully
2023-04-29 11:52:33,026:INFO:Starting cross validation
2023-04-29 11:52:33,026:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 11:52:35,112:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:35,120:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:35,417:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:35,426:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:35,533:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:35,540:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:35,830:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:35,837:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:35,887:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:35,895:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:36,074:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:36,081:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:36,249:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:36,256:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:36,355:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:36,363:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:36,556:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:36,563:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:36,680:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:36,688:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:36,909:INFO:Calculating mean and std
2023-04-29 11:52:36,909:INFO:Creating metrics dataframe
2023-04-29 11:52:36,911:INFO:Finalizing model
2023-04-29 11:52:39,369:INFO:Uploading results into container
2023-04-29 11:52:39,370:INFO:Uploading model into container now
2023-04-29 11:52:39,370:INFO:_master_model_container: 15
2023-04-29 11:52:39,370:INFO:_display_container: 3
2023-04-29 11:52:39,370:INFO:LogisticRegression(C=4.322, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-29 11:52:39,370:INFO:create_model() successfully completed......................................
2023-04-29 11:52:39,424:INFO:SubProcess create_model() end ==================================
2023-04-29 11:52:39,424:INFO:choose_better activated
2023-04-29 11:52:39,424:INFO:SubProcess create_model() called ==================================
2023-04-29 11:52:39,424:INFO:Initializing create_model()
2023-04-29 11:52:39,424:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 11:52:39,425:INFO:Checking exceptions
2023-04-29 11:52:39,425:INFO:Importing libraries
2023-04-29 11:52:39,425:INFO:Copying training dataset
2023-04-29 11:52:39,503:INFO:Defining folds
2023-04-29 11:52:39,503:INFO:Declaring metric variables
2023-04-29 11:52:39,503:INFO:Importing untrained model
2023-04-29 11:52:39,503:INFO:Declaring custom model
2023-04-29 11:52:39,503:INFO:Logistic Regression Imported successfully
2023-04-29 11:52:39,503:INFO:Starting cross validation
2023-04-29 11:52:39,504:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 11:52:43,263:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:43,271:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:43,402:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:43,417:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:43,960:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:43,969:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:44,827:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:44,829:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:44,834:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:44,836:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:44,965:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:44,972:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:45,067:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:45,076:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:45,133:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:45,141:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:45,399:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:45,407:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:45,442:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:45,449:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:52:45,773:INFO:Calculating mean and std
2023-04-29 11:52:45,773:INFO:Creating metrics dataframe
2023-04-29 11:52:45,774:INFO:Finalizing model
2023-04-29 11:52:47,284:INFO:Uploading results into container
2023-04-29 11:52:47,285:INFO:Uploading model into container now
2023-04-29 11:52:47,285:INFO:_master_model_container: 16
2023-04-29 11:52:47,285:INFO:_display_container: 4
2023-04-29 11:52:47,285:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-29 11:52:47,285:INFO:create_model() successfully completed......................................
2023-04-29 11:52:47,338:INFO:SubProcess create_model() end ==================================
2023-04-29 11:52:47,338:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for F1_score is 0.0
2023-04-29 11:52:47,338:INFO:LogisticRegression(C=4.322, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for F1_score is 0.0
2023-04-29 11:52:47,339:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2023-04-29 11:52:47,339:INFO:choose_better completed
2023-04-29 11:52:47,339:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-29 11:52:47,346:INFO:_master_model_container: 16
2023-04-29 11:52:47,346:INFO:_display_container: 3
2023-04-29 11:52:47,346:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-29 11:52:47,346:INFO:tune_model() successfully completed......................................
2023-04-29 11:52:47,415:INFO:Initializing tune_model()
2023-04-29 11:52:47,415:INFO:tune_model(estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1_score, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>)
2023-04-29 11:52:47,415:INFO:Checking exceptions
2023-04-29 11:52:47,452:INFO:Copying training dataset
2023-04-29 11:52:47,500:INFO:Checking base model
2023-04-29 11:52:47,500:INFO:Base model : K Neighbors Classifier
2023-04-29 11:52:47,500:INFO:Declaring metric variables
2023-04-29 11:52:47,500:INFO:Defining Hyperparameters
2023-04-29 11:52:47,551:INFO:Tuning with n_jobs=-1
2023-04-29 11:52:47,551:INFO:Initializing RandomizedSearchCV
2023-04-29 11:53:10,556:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:53:10,633:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:53:10,998:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:53:11,197:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:53:11,590:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:53:11,941:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:53:31,159:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:53:31,632:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:53:31,813:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:53:31,880:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:53:32,412:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:53:32,723:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:53:43,682:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:53:44,069:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:53:44,444:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:53:44,485:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:53:44,810:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:53:45,035:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:53:45,740:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:53:46,086:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:53:46,284:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:53:46,634:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:53:52,210:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:53:52,359:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:53:52,420:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:53:52,898:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:53:53,322:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:53:53,750:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:54:04,582:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:54:05,395:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:54:43,609:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:54:43,817:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:54:43,939:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:54:44,215:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:54:45,068:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:54:45,212:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:54:45,422:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:54:45,600:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:54:51,310:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:54:51,379:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:54:51,648:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:54:51,956:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:54:52,265:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:54:52,816:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:55:03,340:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:55:03,736:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:55:05,986:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:55:06,379:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:55:06,525:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:55:07,088:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:55:12,726:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:55:12,810:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:55:12,820:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:55:13,077:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:55:13,982:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:55:14,290:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:55:35,190:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:55:35,378:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:55:41,499:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:55:41,543:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:55:42,180:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:55:42,500:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:55:55,759:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:55:56,062:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:56:01,190:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:56:01,329:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:56:02,296:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:56:02,676:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:56:03,124:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:56:03,160:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:56:03,248:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:56:03,940:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:56:04,349:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:56:05,056:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:56:10,667:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:56:10,995:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:56:11,123:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:56:11,753:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:56:16,730:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:56:17,918:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:57:00,362:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:57:01,122:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:57:01,687:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:57:02,502:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:57:02,948:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:57:03,116:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:57:03,252:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:57:03,411:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:57:04,299:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:57:04,329:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:57:07,932:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:57:07,956:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:57:08,131:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:57:08,759:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:57:11,339:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:57:11,610:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:57:33,654:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:57:34,196:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:57:34,635:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:57:35,177:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:57:35,429:INFO:best_params: {'actual_estimator__weights': 'uniform', 'actual_estimator__n_neighbors': 48, 'actual_estimator__metric': 'manhattan'}
2023-04-29 11:57:35,429:INFO:Hyperparameter search completed
2023-04-29 11:57:35,429:INFO:SubProcess create_model() called ==================================
2023-04-29 11:57:35,429:INFO:Initializing create_model()
2023-04-29 11:57:35,429:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D5A2388E0>, model_only=True, return_train_score=False, kwargs={'weights': 'uniform', 'n_neighbors': 48, 'metric': 'manhattan'})
2023-04-29 11:57:35,429:INFO:Checking exceptions
2023-04-29 11:57:35,429:INFO:Importing libraries
2023-04-29 11:57:35,429:INFO:Copying training dataset
2023-04-29 11:57:35,520:INFO:Defining folds
2023-04-29 11:57:35,520:INFO:Declaring metric variables
2023-04-29 11:57:35,520:INFO:Importing untrained model
2023-04-29 11:57:35,520:INFO:Declaring custom model
2023-04-29 11:57:35,520:INFO:K Neighbors Classifier Imported successfully
2023-04-29 11:57:35,521:INFO:Starting cross validation
2023-04-29 11:57:35,521:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 11:58:57,105:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:58:57,111:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:58:57,112:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:58:57,117:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:58:57,410:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:58:57,418:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:58:57,508:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:58:57,516:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:58:57,569:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:58:57,576:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:58:57,961:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:58:57,969:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:58:58,078:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:58:58,085:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:58:58,681:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:58:58,689:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:58:58,758:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:58:58,766:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:58:59,278:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:58:59,286:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:58:59,610:INFO:Calculating mean and std
2023-04-29 11:58:59,610:INFO:Creating metrics dataframe
2023-04-29 11:58:59,611:INFO:Finalizing model
2023-04-29 11:59:01,128:INFO:Uploading results into container
2023-04-29 11:59:01,128:INFO:Uploading model into container now
2023-04-29 11:59:01,129:INFO:_master_model_container: 17
2023-04-29 11:59:01,129:INFO:_display_container: 4
2023-04-29 11:59:01,129:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=-1, n_neighbors=48, p=2,
                     weights='uniform')
2023-04-29 11:59:01,129:INFO:create_model() successfully completed......................................
2023-04-29 11:59:01,183:INFO:SubProcess create_model() end ==================================
2023-04-29 11:59:01,183:INFO:choose_better activated
2023-04-29 11:59:01,183:INFO:SubProcess create_model() called ==================================
2023-04-29 11:59:01,183:INFO:Initializing create_model()
2023-04-29 11:59:01,183:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 11:59:01,183:INFO:Checking exceptions
2023-04-29 11:59:01,184:INFO:Importing libraries
2023-04-29 11:59:01,184:INFO:Copying training dataset
2023-04-29 11:59:01,279:INFO:Defining folds
2023-04-29 11:59:01,279:INFO:Declaring metric variables
2023-04-29 11:59:01,279:INFO:Importing untrained model
2023-04-29 11:59:01,279:INFO:Declaring custom model
2023-04-29 11:59:01,279:INFO:K Neighbors Classifier Imported successfully
2023-04-29 11:59:01,279:INFO:Starting cross validation
2023-04-29 11:59:01,280:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 11:59:28,035:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:59:28,043:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:59:28,840:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:59:28,849:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:59:28,860:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:59:28,867:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:59:29,197:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:59:29,204:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:59:29,241:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:59:29,249:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:59:29,479:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:59:29,487:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:59:29,888:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:59:29,895:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:59:30,223:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:59:30,231:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:59:30,289:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:59:30,296:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:59:30,455:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:59:30,462:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 11:59:30,689:INFO:Calculating mean and std
2023-04-29 11:59:30,689:INFO:Creating metrics dataframe
2023-04-29 11:59:30,690:INFO:Finalizing model
2023-04-29 11:59:32,185:INFO:Uploading results into container
2023-04-29 11:59:32,185:INFO:Uploading model into container now
2023-04-29 11:59:32,185:INFO:_master_model_container: 18
2023-04-29 11:59:32,185:INFO:_display_container: 5
2023-04-29 11:59:32,186:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-29 11:59:32,186:INFO:create_model() successfully completed......................................
2023-04-29 11:59:32,241:INFO:SubProcess create_model() end ==================================
2023-04-29 11:59:32,241:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') result for F1_score is 0.0
2023-04-29 11:59:32,242:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=-1, n_neighbors=48, p=2,
                     weights='uniform') result for F1_score is 0.0
2023-04-29 11:59:32,242:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') is best model
2023-04-29 11:59:32,242:INFO:choose_better completed
2023-04-29 11:59:32,242:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-29 11:59:32,249:INFO:_master_model_container: 18
2023-04-29 11:59:32,249:INFO:_display_container: 4
2023-04-29 11:59:32,249:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-29 11:59:32,249:INFO:tune_model() successfully completed......................................
2023-04-29 11:59:32,316:INFO:Initializing blend_models()
2023-04-29 11:59:32,316:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>, estimator_list=[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')], fold=5, round=4, choose_better=False, optimize=f1_score, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-04-29 11:59:32,316:INFO:Checking exceptions
2023-04-29 11:59:32,356:INFO:Importing libraries
2023-04-29 11:59:32,356:INFO:Copying training dataset
2023-04-29 11:59:32,358:INFO:Getting model names
2023-04-29 11:59:32,358:INFO:SubProcess create_model() called ==================================
2023-04-29 11:59:32,359:INFO:Initializing create_model()
2023-04-29 11:59:32,359:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=8245,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('K Neighbors Classifier',
                              KNeighborsClassifier(algorithm='auto',
                                                   leaf_size=30,
                                                   metric='minkowski',
                                                   metric_params=None,
                                                   n_jobs=-1, n_neighbors=5,
                                                   p=2, weights='uniform'))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D0B5E6940>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 11:59:32,359:INFO:Checking exceptions
2023-04-29 11:59:32,359:INFO:Importing libraries
2023-04-29 11:59:32,359:INFO:Copying training dataset
2023-04-29 11:59:32,431:INFO:Defining folds
2023-04-29 11:59:32,431:INFO:Declaring metric variables
2023-04-29 11:59:32,431:INFO:Importing untrained model
2023-04-29 11:59:32,431:INFO:Declaring custom model
2023-04-29 11:59:32,432:INFO:Voting Classifier Imported successfully
2023-04-29 11:59:32,432:INFO:Starting cross validation
2023-04-29 11:59:32,433:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 12:00:10,371:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:00:10,384:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:00:10,527:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:00:10,541:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:00:10,631:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:00:10,646:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:00:10,747:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:00:10,763:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:00:11,226:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:00:11,241:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:00:11,567:INFO:Calculating mean and std
2023-04-29 12:00:11,567:INFO:Creating metrics dataframe
2023-04-29 12:00:11,569:INFO:Finalizing model
2023-04-29 12:00:14,050:INFO:Uploading results into container
2023-04-29 12:00:14,051:INFO:Uploading model into container now
2023-04-29 12:00:14,051:INFO:_master_model_container: 19
2023-04-29 12:00:14,051:INFO:_display_container: 5
2023-04-29 12:00:14,052:INFO:VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=8245,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('K Neighbors Classifier',
                              KNeighborsClassifier(algorithm='auto',
                                                   leaf_size=30,
                                                   metric='minkowski',
                                                   metric_params=None,
                                                   n_jobs=-1, n_neighbors=5,
                                                   p=2, weights='uniform'))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-04-29 12:00:14,052:INFO:create_model() successfully completed......................................
2023-04-29 12:00:14,108:INFO:SubProcess create_model() end ==================================
2023-04-29 12:00:14,113:INFO:_master_model_container: 19
2023-04-29 12:00:14,113:INFO:_display_container: 5
2023-04-29 12:00:14,114:INFO:VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=8245,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('K Neighbors Classifier',
                              KNeighborsClassifier(algorithm='auto',
                                                   leaf_size=30,
                                                   metric='minkowski',
                                                   metric_params=None,
                                                   n_jobs=-1, n_neighbors=5,
                                                   p=2, weights='uniform'))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-04-29 12:00:14,114:INFO:blend_models() successfully completed......................................
2023-04-29 12:00:14,147:INFO:Initializing finalize_model()
2023-04-29 12:00:14,147:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=8245,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('K Neighbors Classifier',
                              KNeighborsClassifier(algorithm='auto',
                                                   leaf_size=30,
                                                   metric='minkowski',
                                                   metric_params=None,
                                                   n_jobs=-1, n_neighbors=5,
                                                   p=2, weights='uniform'))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-29 12:00:14,149:INFO:Finalizing VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=8245,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('K Neighbors Classifier',
                              KNeighborsClassifier(algorithm='auto',
                                                   leaf_size=30,
                                                   metric='minkowski',
                                                   metric_params=None,
                                                   n_jobs=-1, n_neighbors=5,
                                                   p=2, weights='uniform'))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-04-29 12:00:14,161:INFO:Initializing create_model()
2023-04-29 12:00:14,161:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=8245,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('K Neighbors Classifier',
                              KNeighborsClassifier(algorithm='auto',
                                                   leaf_size=30,
                                                   metric='minkowski',
                                                   metric_params=None,
                                                   n_jobs=-1, n_neighbors=5,
                                                   p=2, weights='uniform'))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-29 12:00:14,161:INFO:Checking exceptions
2023-04-29 12:00:14,161:INFO:Importing libraries
2023-04-29 12:00:14,162:INFO:Copying training dataset
2023-04-29 12:00:14,163:INFO:Defining folds
2023-04-29 12:00:14,163:INFO:Declaring metric variables
2023-04-29 12:00:14,163:INFO:Importing untrained model
2023-04-29 12:00:14,163:INFO:Declaring custom model
2023-04-29 12:00:14,164:INFO:Voting Classifier Imported successfully
2023-04-29 12:00:14,164:INFO:Cross validation set to False
2023-04-29 12:00:14,164:INFO:Fitting Model
2023-04-29 12:00:17,427:INFO:Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Month', 'Day_of_Month',
                                             'Estimated_Departure_Time',
                                             'Estimated_Arrival_Time',
                                             'Cancelled', 'Diverted'...
                                                                  n_jobs=None,
                                                                  penalty='l2',
                                                                  random_state=8245,
                                                                  solver='lbfgs',
                                                                  tol=0.0001,
                                                                  verbose=0,
                                                                  warm_start=False)),
                                              ('K Neighbors Classifier',
                                               KNeighborsClassifier(algorithm='auto',
                                                                    leaf_size=30,
                                                                    metric='minkowski',
                                                                    metric_params=None,
                                                                    n_jobs=-1,
                                                                    n_neighbors=5,
                                                                    p=2,
                                                                    weights='uniform'))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-04-29 12:00:17,427:INFO:create_model() successfully completed......................................
2023-04-29 12:00:17,477:INFO:_master_model_container: 19
2023-04-29 12:00:17,477:INFO:_display_container: 5
2023-04-29 12:00:17,481:INFO:Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Month', 'Day_of_Month',
                                             'Estimated_Departure_Time',
                                             'Estimated_Arrival_Time',
                                             'Cancelled', 'Diverted'...
                                                                  n_jobs=None,
                                                                  penalty='l2',
                                                                  random_state=8245,
                                                                  solver='lbfgs',
                                                                  tol=0.0001,
                                                                  verbose=0,
                                                                  warm_start=False)),
                                              ('K Neighbors Classifier',
                                               KNeighborsClassifier(algorithm='auto',
                                                                    leaf_size=30,
                                                                    metric='minkowski',
                                                                    metric_params=None,
                                                                    n_jobs=-1,
                                                                    n_neighbors=5,
                                                                    p=2,
                                                                    weights='uniform'))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-04-29 12:00:17,481:INFO:finalize_model() successfully completed......................................
2023-04-29 12:00:17,508:INFO:Initializing get_config()
2023-04-29 12:00:17,508:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D2EAF35B0>, variable=prep_pipe)
2023-04-29 12:06:50,081:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:06:50,081:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:06:50,081:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:06:50,081:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:06:50,442:INFO:Soft dependency imported: prophet: 1.1.2
2023-04-29 12:06:56,589:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:06:56,589:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:06:56,589:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:06:56,589:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:06:56,947:INFO:Soft dependency imported: prophet: 1.1.2
2023-04-29 12:07:04,475:INFO:PyCaret ClassificationExperiment
2023-04-29 12:07:04,476:INFO:Logging name: clf-default-name
2023-04-29 12:07:04,476:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-29 12:07:04,476:INFO:version 3.0.0
2023-04-29 12:07:04,476:INFO:Initializing setup()
2023-04-29 12:07:04,476:INFO:self.USI: 3994
2023-04-29 12:07:04,476:INFO:self._variable_keys: {'logging_param', 'gpu_n_jobs_param', 'is_multiclass', 'n_jobs_param', 'target_param', 'gpu_param', 'html_param', '_available_plots', 'idx', 'fold_shuffle_param', 'y_train', 'USI', 'seed', 'fold_generator', 'fold_groups_param', 'fix_imbalance', 'X_test', 'y_test', 'memory', 'X_train', 'exp_id', 'pipeline', 'data', 'X', '_ml_usecase', 'exp_name_log', 'log_plots_param', 'y'}
2023-04-29 12:07:04,476:INFO:Checking environment
2023-04-29 12:07:04,476:INFO:python_version: 3.9.12
2023-04-29 12:07:04,476:INFO:python_build: ('main', 'Apr  4 2022 05:22:27')
2023-04-29 12:07:04,476:INFO:machine: AMD64
2023-04-29 12:07:04,483:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-29 12:07:04,485:INFO:Memory: svmem(total=67772514304, available=58152009728, percent=14.2, used=9620504576, free=58152009728)
2023-04-29 12:07:04,485:INFO:Physical Core: 8
2023-04-29 12:07:04,485:INFO:Logical Core: 16
2023-04-29 12:07:04,485:INFO:Checking libraries
2023-04-29 12:07:04,485:INFO:System:
2023-04-29 12:07:04,485:INFO:    python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]
2023-04-29 12:07:04,485:INFO:executable: C:\Users\Administrator\anaconda3\envs\tf274gpu\python.exe
2023-04-29 12:07:04,485:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-29 12:07:04,485:INFO:PyCaret required dependencies:
2023-04-29 12:07:04,485:INFO:                 pip: 21.2.4
2023-04-29 12:07:04,485:INFO:          setuptools: 61.2.0
2023-04-29 12:07:04,485:INFO:             pycaret: 3.0.0
2023-04-29 12:07:04,485:INFO:             IPython: 7.34.0
2023-04-29 12:07:04,485:INFO:          ipywidgets: 7.6.5
2023-04-29 12:07:04,485:INFO:                tqdm: 4.64.0
2023-04-29 12:07:04,485:INFO:               numpy: 1.21.6
2023-04-29 12:07:04,485:INFO:              pandas: 1.5.3
2023-04-29 12:07:04,485:INFO:              jinja2: 3.1.2
2023-04-29 12:07:04,485:INFO:               scipy: 1.9.1
2023-04-29 12:07:04,485:INFO:              joblib: 1.2.0
2023-04-29 12:07:04,485:INFO:             sklearn: 1.2.2
2023-04-29 12:07:04,485:INFO:                pyod: 1.0.9
2023-04-29 12:07:04,485:INFO:            imblearn: 0.10.1
2023-04-29 12:07:04,485:INFO:   category_encoders: 2.6.0
2023-04-29 12:07:04,485:INFO:            lightgbm: 3.3.5
2023-04-29 12:07:04,485:INFO:               numba: 0.55.1
2023-04-29 12:07:04,485:INFO:            requests: 2.27.1
2023-04-29 12:07:04,485:INFO:          matplotlib: 3.5.1
2023-04-29 12:07:04,485:INFO:          scikitplot: 0.3.7
2023-04-29 12:07:04,485:INFO:         yellowbrick: 1.5
2023-04-29 12:07:04,485:INFO:              plotly: 5.14.1
2023-04-29 12:07:04,485:INFO:             kaleido: 0.2.1
2023-04-29 12:07:04,485:INFO:         statsmodels: 0.13.2
2023-04-29 12:07:04,485:INFO:              sktime: 0.17.2
2023-04-29 12:07:04,485:INFO:               tbats: 1.1.3
2023-04-29 12:07:04,485:INFO:            pmdarima: 2.0.3
2023-04-29 12:07:04,485:INFO:              psutil: 5.9.5
2023-04-29 12:07:04,485:INFO:PyCaret optional dependencies:
2023-04-29 12:07:04,490:INFO:                shap: Not installed
2023-04-29 12:07:04,490:INFO:           interpret: Not installed
2023-04-29 12:07:04,490:INFO:                umap: Not installed
2023-04-29 12:07:04,490:INFO:    pandas_profiling: Not installed
2023-04-29 12:07:04,490:INFO:  explainerdashboard: Not installed
2023-04-29 12:07:04,490:INFO:             autoviz: Not installed
2023-04-29 12:07:04,490:INFO:           fairlearn: Not installed
2023-04-29 12:07:04,490:INFO:             xgboost: 1.7.5
2023-04-29 12:07:04,490:INFO:            catboost: 1.1.1
2023-04-29 12:07:04,490:INFO:              kmodes: Not installed
2023-04-29 12:07:04,490:INFO:             mlxtend: Not installed
2023-04-29 12:07:04,490:INFO:       statsforecast: Not installed
2023-04-29 12:07:04,490:INFO:        tune_sklearn: Not installed
2023-04-29 12:07:04,490:INFO:                 ray: Not installed
2023-04-29 12:07:04,490:INFO:            hyperopt: Not installed
2023-04-29 12:07:04,490:INFO:              optuna: 3.1.1
2023-04-29 12:07:04,490:INFO:               skopt: Not installed
2023-04-29 12:07:04,490:INFO:              mlflow: Not installed
2023-04-29 12:07:04,490:INFO:              gradio: Not installed
2023-04-29 12:07:04,490:INFO:             fastapi: Not installed
2023-04-29 12:07:04,490:INFO:             uvicorn: Not installed
2023-04-29 12:07:04,490:INFO:              m2cgen: Not installed
2023-04-29 12:07:04,490:INFO:           evidently: Not installed
2023-04-29 12:07:04,490:INFO:               fugue: Not installed
2023-04-29 12:07:04,490:INFO:           streamlit: Not installed
2023-04-29 12:07:04,490:INFO:             prophet: 1.1.2
2023-04-29 12:07:04,490:INFO:None
2023-04-29 12:07:04,490:INFO:Set up data.
2023-04-29 12:07:04,565:INFO:Set up train/test split.
2023-04-29 12:07:04,690:INFO:Set up index.
2023-04-29 12:07:04,692:INFO:Set up folding strategy.
2023-04-29 12:07:04,692:INFO:Assigning column types.
2023-04-29 12:07:04,711:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 12:07:04,736:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 12:07:04,737:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 12:07:04,755:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 12:07:04,776:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 12:07:04,811:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 12:07:04,811:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 12:07:04,826:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 12:07:04,827:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 12:07:04,828:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 12:07:04,852:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 12:07:04,872:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 12:07:04,874:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 12:07:04,902:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 12:07:04,917:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 12:07:04,918:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 12:07:04,919:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-29 12:07:04,958:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 12:07:04,959:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 12:07:04,999:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 12:07:05,000:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 12:07:05,001:INFO:Preparing preprocessing pipeline...
2023-04-29 12:07:05,005:INFO:Set up label encoding.
2023-04-29 12:07:05,005:INFO:Set up simple imputation.
2023-04-29 12:07:05,008:INFO:Set up column name cleaning.
2023-04-29 12:07:06,250:INFO:Finished creating preprocessing pipeline.
2023-04-29 12:07:06,254:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Month', 'Day_of_Month',
                                             'Estimated_Departure_Time',
                                             'Estimated_Arrival_Time',
                                             'Cancelled', 'Diverted'...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-04-29 12:07:06,254:INFO:Creating final display dataframe.
2023-04-29 12:07:06,959:INFO:Setup _display_container:                     Description                       Value
0                    Session id                        8245
1                        Target                       Delay
2                   Target type                      Binary
3                Target mapping  Delayed: 0, Not_Delayed: 1
4           Original data shape                (255001, 18)
5        Transformed data shape                (255001, 18)
6   Transformed train set shape                (204000, 18)
7    Transformed test set shape                 (51001, 18)
8              Numeric features                          17
9                    Preprocess                        True
10              Imputation type                      simple
11           Numeric imputation                        mean
12       Categorical imputation                        mode
13               Fold Generator             StratifiedKFold
14                  Fold Number                          10
15                     CPU Jobs                          -1
16                      Use GPU                       False
17               Log Experiment                       False
18              Experiment Name            clf-default-name
19                          USI                        3994
2023-04-29 12:07:07,002:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 12:07:07,003:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 12:07:07,043:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 12:07:07,045:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 12:07:07,045:INFO:setup() successfully completed in 2.6s...............
2023-04-29 12:07:07,046:INFO:Initializing compare_models()
2023-04-29 12:07:07,046:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFF962370>, include=None, fold=5, round=4, cross_validation=True, sort=f1_score, n_select=2, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFF962370>, 'include': None, 'exclude': ['svm', 'ridge'], 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'f1_score', 'n_select': 2, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['svm', 'ridge'])
2023-04-29 12:07:07,046:INFO:Checking exceptions
2023-04-29 12:07:07,087:INFO:Preparing display monitor
2023-04-29 12:07:07,089:INFO:Initializing Logistic Regression
2023-04-29 12:07:07,089:INFO:Total runtime is 0.0 minutes
2023-04-29 12:07:07,089:INFO:SubProcess create_model() called ==================================
2023-04-29 12:07:07,089:INFO:Initializing create_model()
2023-04-29 12:07:07,089:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFF962370>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCA36C220>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:07:07,089:INFO:Checking exceptions
2023-04-29 12:07:07,089:INFO:Importing libraries
2023-04-29 12:07:07,089:INFO:Copying training dataset
2023-04-29 12:07:07,168:INFO:Defining folds
2023-04-29 12:07:07,168:INFO:Declaring metric variables
2023-04-29 12:07:07,168:INFO:Importing untrained model
2023-04-29 12:07:07,169:INFO:Logistic Regression Imported successfully
2023-04-29 12:07:07,169:INFO:Starting cross validation
2023-04-29 12:07:07,169:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 12:07:11,678:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:11,694:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:11,764:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:11,780:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:11,876:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:11,892:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:12,020:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:12,036:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:12,065:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:12,082:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:12,307:INFO:Calculating mean and std
2023-04-29 12:07:12,308:INFO:Creating metrics dataframe
2023-04-29 12:07:12,341:INFO:Uploading results into container
2023-04-29 12:07:12,341:INFO:Uploading model into container now
2023-04-29 12:07:12,341:INFO:_master_model_container: 1
2023-04-29 12:07:12,341:INFO:_display_container: 2
2023-04-29 12:07:12,341:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-29 12:07:12,341:INFO:create_model() successfully completed......................................
2023-04-29 12:07:12,392:INFO:SubProcess create_model() end ==================================
2023-04-29 12:07:12,393:INFO:Creating metrics dataframe
2023-04-29 12:07:12,394:INFO:Initializing K Neighbors Classifier
2023-04-29 12:07:12,394:INFO:Total runtime is 0.08841704527537028 minutes
2023-04-29 12:07:12,394:INFO:SubProcess create_model() called ==================================
2023-04-29 12:07:12,394:INFO:Initializing create_model()
2023-04-29 12:07:12,394:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFF962370>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCA36C220>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:07:12,394:INFO:Checking exceptions
2023-04-29 12:07:12,396:INFO:Importing libraries
2023-04-29 12:07:12,396:INFO:Copying training dataset
2023-04-29 12:07:12,477:INFO:Defining folds
2023-04-29 12:07:12,477:INFO:Declaring metric variables
2023-04-29 12:07:12,477:INFO:Importing untrained model
2023-04-29 12:07:12,477:INFO:K Neighbors Classifier Imported successfully
2023-04-29 12:07:12,477:INFO:Starting cross validation
2023-04-29 12:07:12,478:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 12:07:51,492:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:51,508:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:51,548:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:51,564:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:51,612:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:51,628:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:51,732:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:51,749:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:51,794:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:51,812:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:52,040:INFO:Calculating mean and std
2023-04-29 12:07:52,041:INFO:Creating metrics dataframe
2023-04-29 12:07:52,074:INFO:Uploading results into container
2023-04-29 12:07:52,075:INFO:Uploading model into container now
2023-04-29 12:07:52,075:INFO:_master_model_container: 2
2023-04-29 12:07:52,075:INFO:_display_container: 2
2023-04-29 12:07:52,075:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-29 12:07:52,075:INFO:create_model() successfully completed......................................
2023-04-29 12:07:52,136:INFO:SubProcess create_model() end ==================================
2023-04-29 12:07:52,136:INFO:Creating metrics dataframe
2023-04-29 12:07:52,138:INFO:Initializing Naive Bayes
2023-04-29 12:07:52,138:INFO:Total runtime is 0.7508164366086324 minutes
2023-04-29 12:07:52,139:INFO:SubProcess create_model() called ==================================
2023-04-29 12:07:52,139:INFO:Initializing create_model()
2023-04-29 12:07:52,139:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFF962370>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCA36C220>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:07:52,139:INFO:Checking exceptions
2023-04-29 12:07:52,139:INFO:Importing libraries
2023-04-29 12:07:52,139:INFO:Copying training dataset
2023-04-29 12:07:52,224:INFO:Defining folds
2023-04-29 12:07:52,224:INFO:Declaring metric variables
2023-04-29 12:07:52,225:INFO:Importing untrained model
2023-04-29 12:07:52,225:INFO:Naive Bayes Imported successfully
2023-04-29 12:07:52,225:INFO:Starting cross validation
2023-04-29 12:07:52,225:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 12:07:55,821:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:55,838:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:55,855:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:55,872:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:55,920:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:55,937:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:56,011:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:56,026:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:56,087:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:56,104:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:07:56,429:INFO:Calculating mean and std
2023-04-29 12:07:56,430:INFO:Creating metrics dataframe
2023-04-29 12:07:56,462:INFO:Uploading results into container
2023-04-29 12:07:56,463:INFO:Uploading model into container now
2023-04-29 12:07:56,463:INFO:_master_model_container: 3
2023-04-29 12:07:56,463:INFO:_display_container: 2
2023-04-29 12:07:56,463:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-29 12:07:56,463:INFO:create_model() successfully completed......................................
2023-04-29 12:07:56,515:INFO:SubProcess create_model() end ==================================
2023-04-29 12:07:56,515:INFO:Creating metrics dataframe
2023-04-29 12:07:56,517:INFO:Initializing Decision Tree Classifier
2023-04-29 12:07:56,517:INFO:Total runtime is 0.8238047440846761 minutes
2023-04-29 12:07:56,518:INFO:SubProcess create_model() called ==================================
2023-04-29 12:07:56,518:INFO:Initializing create_model()
2023-04-29 12:07:56,518:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFF962370>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCA36C220>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:07:56,518:INFO:Checking exceptions
2023-04-29 12:07:56,518:INFO:Importing libraries
2023-04-29 12:07:56,518:INFO:Copying training dataset
2023-04-29 12:07:56,608:INFO:Defining folds
2023-04-29 12:07:56,608:INFO:Declaring metric variables
2023-04-29 12:07:56,608:INFO:Importing untrained model
2023-04-29 12:07:56,609:INFO:Decision Tree Classifier Imported successfully
2023-04-29 12:07:56,609:INFO:Starting cross validation
2023-04-29 12:07:56,609:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 12:07:58,852:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 5, in union1d
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 777, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 5, in unique
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 272, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 333, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'float' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=['Delayed' 'Not_Delayed'] and y_pred=[0. 1.]. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2023-04-29 12:07:58,881:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 5, in union1d
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 777, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 5, in unique
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 272, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 333, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'float' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=['Delayed' 'Not_Delayed'] and y_pred=[0. 1.]. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2023-04-29 12:07:58,900:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 5, in union1d
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 777, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 5, in unique
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 272, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 333, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'float' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=['Delayed' 'Not_Delayed'] and y_pred=[0. 1.]. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2023-04-29 12:07:58,927:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 5, in union1d
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 777, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 5, in unique
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 272, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 333, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'float' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=['Delayed' 'Not_Delayed'] and y_pred=[0. 1.]. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2023-04-29 12:07:59,014:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 5, in union1d
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 777, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 5, in unique
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 272, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 333, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'float' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=['Delayed' 'Not_Delayed'] and y_pred=[0. 1.]. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2023-04-29 12:07:59,042:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 5, in union1d
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 777, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 5, in unique
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 272, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 333, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'float' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=['Delayed' 'Not_Delayed'] and y_pred=[0. 1.]. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2023-04-29 12:07:59,131:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 5, in union1d
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 777, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 5, in unique
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 272, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 333, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'float' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=['Delayed' 'Not_Delayed'] and y_pred=[0. 1.]. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2023-04-29 12:07:59,160:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 5, in union1d
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 777, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 5, in unique
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 272, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 333, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'float' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=['Delayed' 'Not_Delayed'] and y_pred=[0. 1.]. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2023-04-29 12:08:00,051:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 5, in union1d
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 777, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 5, in unique
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 272, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 333, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'float' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=['Delayed' 'Not_Delayed'] and y_pred=[0. 1.]. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2023-04-29 12:08:00,080:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 5, in union1d
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 777, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 5, in unique
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 272, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\numpy\lib\arraysetops.py", line 333, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'float' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=['Delayed' 'Not_Delayed'] and y_pred=[0. 1.]. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(

2023-04-29 12:08:00,409:INFO:Calculating mean and std
2023-04-29 12:08:00,410:INFO:Creating metrics dataframe
2023-04-29 12:08:00,442:INFO:Uploading results into container
2023-04-29 12:08:00,442:INFO:Uploading model into container now
2023-04-29 12:08:00,442:INFO:_master_model_container: 4
2023-04-29 12:08:00,442:INFO:_display_container: 2
2023-04-29 12:08:00,442:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8245, splitter='best')
2023-04-29 12:08:00,442:INFO:create_model() successfully completed......................................
2023-04-29 12:08:00,493:INFO:SubProcess create_model() end ==================================
2023-04-29 12:08:00,493:INFO:Creating metrics dataframe
2023-04-29 12:08:00,495:INFO:Initializing Random Forest Classifier
2023-04-29 12:08:00,495:INFO:Total runtime is 0.8901061574618021 minutes
2023-04-29 12:08:00,495:INFO:SubProcess create_model() called ==================================
2023-04-29 12:08:00,495:INFO:Initializing create_model()
2023-04-29 12:08:00,495:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFF962370>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCA36C220>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:08:00,495:INFO:Checking exceptions
2023-04-29 12:08:00,495:INFO:Importing libraries
2023-04-29 12:08:00,495:INFO:Copying training dataset
2023-04-29 12:08:00,576:INFO:Defining folds
2023-04-29 12:08:00,576:INFO:Declaring metric variables
2023-04-29 12:08:00,576:INFO:Importing untrained model
2023-04-29 12:08:00,577:INFO:Random Forest Classifier Imported successfully
2023-04-29 12:08:00,577:INFO:Starting cross validation
2023-04-29 12:08:00,577:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 12:08:03,441:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:03,496:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:03,538:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:03,552:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:03,667:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:03,682:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:03,904:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:03,920:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:04,114:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:04,129:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:04,350:INFO:Calculating mean and std
2023-04-29 12:08:04,351:INFO:Creating metrics dataframe
2023-04-29 12:08:04,384:INFO:Uploading results into container
2023-04-29 12:08:04,385:INFO:Uploading model into container now
2023-04-29 12:08:04,385:INFO:_master_model_container: 5
2023-04-29 12:08:04,385:INFO:_display_container: 2
2023-04-29 12:08:04,385:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8245, verbose=0, warm_start=False)
2023-04-29 12:08:04,385:INFO:create_model() successfully completed......................................
2023-04-29 12:08:04,436:INFO:SubProcess create_model() end ==================================
2023-04-29 12:08:04,436:INFO:Creating metrics dataframe
2023-04-29 12:08:04,439:INFO:Initializing Quadratic Discriminant Analysis
2023-04-29 12:08:04,439:INFO:Total runtime is 0.9558397253354389 minutes
2023-04-29 12:08:04,439:INFO:SubProcess create_model() called ==================================
2023-04-29 12:08:04,439:INFO:Initializing create_model()
2023-04-29 12:08:04,439:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFF962370>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCA36C220>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:08:04,439:INFO:Checking exceptions
2023-04-29 12:08:04,439:INFO:Importing libraries
2023-04-29 12:08:04,439:INFO:Copying training dataset
2023-04-29 12:08:04,529:INFO:Defining folds
2023-04-29 12:08:04,529:INFO:Declaring metric variables
2023-04-29 12:08:04,529:INFO:Importing untrained model
2023-04-29 12:08:04,529:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-29 12:08:04,529:INFO:Starting cross validation
2023-04-29 12:08:04,530:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 12:08:05,928:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:08:05,994:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:08:06,194:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:08:06,332:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:08:06,436:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:08:06,770:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:06,785:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:06,832:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:06,849:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:07,003:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:07,019:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:07,126:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:07,140:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:07,242:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:07,258:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:07,483:INFO:Calculating mean and std
2023-04-29 12:08:07,484:INFO:Creating metrics dataframe
2023-04-29 12:08:07,517:INFO:Uploading results into container
2023-04-29 12:08:07,517:INFO:Uploading model into container now
2023-04-29 12:08:07,517:INFO:_master_model_container: 6
2023-04-29 12:08:07,517:INFO:_display_container: 2
2023-04-29 12:08:07,517:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-29 12:08:07,517:INFO:create_model() successfully completed......................................
2023-04-29 12:08:07,581:INFO:SubProcess create_model() end ==================================
2023-04-29 12:08:07,581:INFO:Creating metrics dataframe
2023-04-29 12:08:07,582:INFO:Initializing Ada Boost Classifier
2023-04-29 12:08:07,582:INFO:Total runtime is 1.0082182765007017 minutes
2023-04-29 12:08:07,584:INFO:SubProcess create_model() called ==================================
2023-04-29 12:08:07,584:INFO:Initializing create_model()
2023-04-29 12:08:07,584:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFF962370>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCA36C220>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:08:07,584:INFO:Checking exceptions
2023-04-29 12:08:07,584:INFO:Importing libraries
2023-04-29 12:08:07,584:INFO:Copying training dataset
2023-04-29 12:08:07,679:INFO:Defining folds
2023-04-29 12:08:07,679:INFO:Declaring metric variables
2023-04-29 12:08:07,679:INFO:Importing untrained model
2023-04-29 12:08:07,679:INFO:Ada Boost Classifier Imported successfully
2023-04-29 12:08:07,679:INFO:Starting cross validation
2023-04-29 12:08:07,679:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 12:08:10,258:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:10,274:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:10,325:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:10,341:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:10,443:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:10,458:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:10,637:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:10,652:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:10,712:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:10,728:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:11,055:INFO:Calculating mean and std
2023-04-29 12:08:11,055:INFO:Creating metrics dataframe
2023-04-29 12:08:11,095:INFO:Uploading results into container
2023-04-29 12:08:11,096:INFO:Uploading model into container now
2023-04-29 12:08:11,096:INFO:_master_model_container: 7
2023-04-29 12:08:11,096:INFO:_display_container: 2
2023-04-29 12:08:11,096:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=8245)
2023-04-29 12:08:11,096:INFO:create_model() successfully completed......................................
2023-04-29 12:08:11,151:INFO:SubProcess create_model() end ==================================
2023-04-29 12:08:11,151:INFO:Creating metrics dataframe
2023-04-29 12:08:11,153:INFO:Initializing Gradient Boosting Classifier
2023-04-29 12:08:11,153:INFO:Total runtime is 1.0677363077799478 minutes
2023-04-29 12:08:11,153:INFO:SubProcess create_model() called ==================================
2023-04-29 12:08:11,153:INFO:Initializing create_model()
2023-04-29 12:08:11,153:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFF962370>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCA36C220>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:08:11,153:INFO:Checking exceptions
2023-04-29 12:08:11,153:INFO:Importing libraries
2023-04-29 12:08:11,153:INFO:Copying training dataset
2023-04-29 12:08:11,232:INFO:Defining folds
2023-04-29 12:08:11,232:INFO:Declaring metric variables
2023-04-29 12:08:11,232:INFO:Importing untrained model
2023-04-29 12:08:11,233:INFO:Gradient Boosting Classifier Imported successfully
2023-04-29 12:08:11,233:INFO:Starting cross validation
2023-04-29 12:08:11,233:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 12:08:13,519:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:13,534:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:13,593:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:13,608:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:13,772:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:13,787:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:13,826:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:13,841:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:13,971:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:13,988:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:14,313:INFO:Calculating mean and std
2023-04-29 12:08:14,313:INFO:Creating metrics dataframe
2023-04-29 12:08:14,345:INFO:Uploading results into container
2023-04-29 12:08:14,345:INFO:Uploading model into container now
2023-04-29 12:08:14,345:INFO:_master_model_container: 8
2023-04-29 12:08:14,345:INFO:_display_container: 2
2023-04-29 12:08:14,346:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8245, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-29 12:08:14,346:INFO:create_model() successfully completed......................................
2023-04-29 12:08:14,398:INFO:SubProcess create_model() end ==================================
2023-04-29 12:08:14,398:INFO:Creating metrics dataframe
2023-04-29 12:08:14,401:INFO:Initializing Linear Discriminant Analysis
2023-04-29 12:08:14,401:INFO:Total runtime is 1.1218705614407856 minutes
2023-04-29 12:08:14,401:INFO:SubProcess create_model() called ==================================
2023-04-29 12:08:14,401:INFO:Initializing create_model()
2023-04-29 12:08:14,401:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFF962370>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCA36C220>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:08:14,401:INFO:Checking exceptions
2023-04-29 12:08:14,401:INFO:Importing libraries
2023-04-29 12:08:14,401:INFO:Copying training dataset
2023-04-29 12:08:14,481:INFO:Defining folds
2023-04-29 12:08:14,481:INFO:Declaring metric variables
2023-04-29 12:08:14,481:INFO:Importing untrained model
2023-04-29 12:08:14,481:INFO:Linear Discriminant Analysis Imported successfully
2023-04-29 12:08:14,481:INFO:Starting cross validation
2023-04-29 12:08:14,482:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 12:08:16,585:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:16,601:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:16,673:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:16,688:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:16,782:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:16,798:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:16,919:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:16,934:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:17,033:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:17,050:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:17,279:INFO:Calculating mean and std
2023-04-29 12:08:17,279:INFO:Creating metrics dataframe
2023-04-29 12:08:17,311:INFO:Uploading results into container
2023-04-29 12:08:17,311:INFO:Uploading model into container now
2023-04-29 12:08:17,311:INFO:_master_model_container: 9
2023-04-29 12:08:17,311:INFO:_display_container: 2
2023-04-29 12:08:17,311:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-29 12:08:17,311:INFO:create_model() successfully completed......................................
2023-04-29 12:08:17,360:INFO:SubProcess create_model() end ==================================
2023-04-29 12:08:17,360:INFO:Creating metrics dataframe
2023-04-29 12:08:17,362:INFO:Initializing Extra Trees Classifier
2023-04-29 12:08:17,362:INFO:Total runtime is 1.1712121725082396 minutes
2023-04-29 12:08:17,362:INFO:SubProcess create_model() called ==================================
2023-04-29 12:08:17,362:INFO:Initializing create_model()
2023-04-29 12:08:17,362:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFF962370>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCA36C220>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:08:17,362:INFO:Checking exceptions
2023-04-29 12:08:17,362:INFO:Importing libraries
2023-04-29 12:08:17,362:INFO:Copying training dataset
2023-04-29 12:08:17,464:INFO:Defining folds
2023-04-29 12:08:17,465:INFO:Declaring metric variables
2023-04-29 12:08:17,465:INFO:Importing untrained model
2023-04-29 12:08:17,465:INFO:Extra Trees Classifier Imported successfully
2023-04-29 12:08:17,465:INFO:Starting cross validation
2023-04-29 12:08:17,465:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 12:08:21,032:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:21,047:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:21,098:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:21,113:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:21,191:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:21,206:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:21,424:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:21,440:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:21,587:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:21,602:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:21,823:INFO:Calculating mean and std
2023-04-29 12:08:21,824:INFO:Creating metrics dataframe
2023-04-29 12:08:21,856:INFO:Uploading results into container
2023-04-29 12:08:21,856:INFO:Uploading model into container now
2023-04-29 12:08:21,856:INFO:_master_model_container: 10
2023-04-29 12:08:21,856:INFO:_display_container: 2
2023-04-29 12:08:21,856:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=8245, verbose=0, warm_start=False)
2023-04-29 12:08:21,856:INFO:create_model() successfully completed......................................
2023-04-29 12:08:21,906:INFO:SubProcess create_model() end ==================================
2023-04-29 12:08:21,906:INFO:Creating metrics dataframe
2023-04-29 12:08:21,908:INFO:Initializing Extreme Gradient Boosting
2023-04-29 12:08:21,908:INFO:Total runtime is 1.2469735622406004 minutes
2023-04-29 12:08:21,908:INFO:SubProcess create_model() called ==================================
2023-04-29 12:08:21,908:INFO:Initializing create_model()
2023-04-29 12:08:21,908:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFF962370>, estimator=xgboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCA36C220>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:08:21,908:INFO:Checking exceptions
2023-04-29 12:08:21,908:INFO:Importing libraries
2023-04-29 12:08:21,908:INFO:Copying training dataset
2023-04-29 12:08:21,991:INFO:Defining folds
2023-04-29 12:08:21,991:INFO:Declaring metric variables
2023-04-29 12:08:21,992:INFO:Importing untrained model
2023-04-29 12:08:21,992:INFO:Extreme Gradient Boosting Imported successfully
2023-04-29 12:08:21,992:INFO:Starting cross validation
2023-04-29 12:08:21,993:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 12:08:24,272:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:24,288:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:24,363:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:24,378:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:24,421:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:24,437:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:24,622:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:24,637:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:24,729:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:24,745:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:24,965:INFO:Calculating mean and std
2023-04-29 12:08:24,965:INFO:Creating metrics dataframe
2023-04-29 12:08:24,998:INFO:Uploading results into container
2023-04-29 12:08:24,998:INFO:Uploading model into container now
2023-04-29 12:08:24,998:INFO:_master_model_container: 11
2023-04-29 12:08:24,998:INFO:_display_container: 2
2023-04-29 12:08:24,999:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-04-29 12:08:24,999:INFO:create_model() successfully completed......................................
2023-04-29 12:08:25,048:INFO:SubProcess create_model() end ==================================
2023-04-29 12:08:25,048:INFO:Creating metrics dataframe
2023-04-29 12:08:25,050:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 12:08:25,050:INFO:Total runtime is 1.2993409355481464 minutes
2023-04-29 12:08:25,050:INFO:SubProcess create_model() called ==================================
2023-04-29 12:08:25,050:INFO:Initializing create_model()
2023-04-29 12:08:25,050:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFF962370>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCA36C220>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:08:25,050:INFO:Checking exceptions
2023-04-29 12:08:25,050:INFO:Importing libraries
2023-04-29 12:08:25,050:INFO:Copying training dataset
2023-04-29 12:08:25,132:INFO:Defining folds
2023-04-29 12:08:25,132:INFO:Declaring metric variables
2023-04-29 12:08:25,132:INFO:Importing untrained model
2023-04-29 12:08:25,132:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 12:08:25,132:INFO:Starting cross validation
2023-04-29 12:08:25,133:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 12:08:27,810:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:27,825:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:27,906:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:27,920:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:27,993:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:28,009:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:28,097:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:28,112:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:28,172:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:28,195:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:28,421:INFO:Calculating mean and std
2023-04-29 12:08:28,421:INFO:Creating metrics dataframe
2023-04-29 12:08:28,453:INFO:Uploading results into container
2023-04-29 12:08:28,453:INFO:Uploading model into container now
2023-04-29 12:08:28,453:INFO:_master_model_container: 12
2023-04-29 12:08:28,453:INFO:_display_container: 2
2023-04-29 12:08:28,454:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8245, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-29 12:08:28,454:INFO:create_model() successfully completed......................................
2023-04-29 12:08:28,502:INFO:SubProcess create_model() end ==================================
2023-04-29 12:08:28,502:INFO:Creating metrics dataframe
2023-04-29 12:08:28,504:INFO:Initializing CatBoost Classifier
2023-04-29 12:08:28,504:INFO:Total runtime is 1.356917103131612 minutes
2023-04-29 12:08:28,504:INFO:SubProcess create_model() called ==================================
2023-04-29 12:08:28,504:INFO:Initializing create_model()
2023-04-29 12:08:28,504:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFF962370>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCA36C220>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:08:28,504:INFO:Checking exceptions
2023-04-29 12:08:28,504:INFO:Importing libraries
2023-04-29 12:08:28,504:INFO:Copying training dataset
2023-04-29 12:08:28,585:INFO:Defining folds
2023-04-29 12:08:28,586:INFO:Declaring metric variables
2023-04-29 12:08:28,586:INFO:Importing untrained model
2023-04-29 12:08:28,586:INFO:CatBoost Classifier Imported successfully
2023-04-29 12:08:28,586:INFO:Starting cross validation
2023-04-29 12:08:28,586:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 12:08:30,980:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:30,995:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:31,104:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:31,121:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:31,123:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:31,138:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:31,281:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:31,295:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:31,373:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:31,390:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:31,616:INFO:Calculating mean and std
2023-04-29 12:08:31,616:INFO:Creating metrics dataframe
2023-04-29 12:08:31,649:INFO:Uploading results into container
2023-04-29 12:08:31,649:INFO:Uploading model into container now
2023-04-29 12:08:31,649:INFO:_master_model_container: 13
2023-04-29 12:08:31,649:INFO:_display_container: 2
2023-04-29 12:08:31,649:INFO:<catboost.core.CatBoostClassifier object at 0x000001FDC94C9CD0>
2023-04-29 12:08:31,649:INFO:create_model() successfully completed......................................
2023-04-29 12:08:31,699:INFO:SubProcess create_model() end ==================================
2023-04-29 12:08:31,699:INFO:Creating metrics dataframe
2023-04-29 12:08:31,702:INFO:Initializing Dummy Classifier
2023-04-29 12:08:31,702:INFO:Total runtime is 1.4102130810419717 minutes
2023-04-29 12:08:31,702:INFO:SubProcess create_model() called ==================================
2023-04-29 12:08:31,702:INFO:Initializing create_model()
2023-04-29 12:08:31,702:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFF962370>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCA36C220>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:08:31,702:INFO:Checking exceptions
2023-04-29 12:08:31,702:INFO:Importing libraries
2023-04-29 12:08:31,702:INFO:Copying training dataset
2023-04-29 12:08:31,790:INFO:Defining folds
2023-04-29 12:08:31,790:INFO:Declaring metric variables
2023-04-29 12:08:31,790:INFO:Importing untrained model
2023-04-29 12:08:31,791:INFO:Dummy Classifier Imported successfully
2023-04-29 12:08:31,791:INFO:Starting cross validation
2023-04-29 12:08:31,791:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 12:08:33,900:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:33,920:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:33,994:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:34,009:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:34,124:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:34,140:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:34,198:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:34,212:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:34,362:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:34,379:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:34,609:INFO:Calculating mean and std
2023-04-29 12:08:34,609:INFO:Creating metrics dataframe
2023-04-29 12:08:34,645:INFO:Uploading results into container
2023-04-29 12:08:34,646:INFO:Uploading model into container now
2023-04-29 12:08:34,646:INFO:_master_model_container: 14
2023-04-29 12:08:34,646:INFO:_display_container: 2
2023-04-29 12:08:34,646:INFO:DummyClassifier(constant=None, random_state=8245, strategy='prior')
2023-04-29 12:08:34,646:INFO:create_model() successfully completed......................................
2023-04-29 12:08:34,697:INFO:SubProcess create_model() end ==================================
2023-04-29 12:08:34,697:INFO:Creating metrics dataframe
2023-04-29 12:08:34,700:INFO:Initializing create_model()
2023-04-29 12:08:34,700:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFF962370>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:08:34,700:INFO:Checking exceptions
2023-04-29 12:08:34,700:INFO:Importing libraries
2023-04-29 12:08:34,700:INFO:Copying training dataset
2023-04-29 12:08:34,783:INFO:Defining folds
2023-04-29 12:08:34,783:INFO:Declaring metric variables
2023-04-29 12:08:34,783:INFO:Importing untrained model
2023-04-29 12:08:34,783:INFO:Declaring custom model
2023-04-29 12:08:34,784:INFO:Logistic Regression Imported successfully
2023-04-29 12:08:34,784:INFO:Cross validation set to False
2023-04-29 12:08:34,784:INFO:Fitting Model
2023-04-29 12:08:36,321:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-29 12:08:36,321:INFO:create_model() successfully completed......................................
2023-04-29 12:08:36,372:INFO:Initializing create_model()
2023-04-29 12:08:36,372:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFF962370>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:08:36,372:INFO:Checking exceptions
2023-04-29 12:08:36,373:INFO:Importing libraries
2023-04-29 12:08:36,373:INFO:Copying training dataset
2023-04-29 12:08:36,459:INFO:Defining folds
2023-04-29 12:08:36,459:INFO:Declaring metric variables
2023-04-29 12:08:36,459:INFO:Importing untrained model
2023-04-29 12:08:36,459:INFO:Declaring custom model
2023-04-29 12:08:36,459:INFO:K Neighbors Classifier Imported successfully
2023-04-29 12:08:36,460:INFO:Cross validation set to False
2023-04-29 12:08:36,460:INFO:Fitting Model
2023-04-29 12:08:37,981:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-29 12:08:37,981:INFO:create_model() successfully completed......................................
2023-04-29 12:08:38,038:INFO:_master_model_container: 14
2023-04-29 12:08:38,038:INFO:_display_container: 2
2023-04-29 12:08:38,038:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')]
2023-04-29 12:08:38,039:INFO:compare_models() successfully completed......................................
2023-04-29 12:08:38,039:INFO:Initializing tune_model()
2023-04-29 12:08:38,039:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1_score, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFF962370>)
2023-04-29 12:08:38,039:INFO:Checking exceptions
2023-04-29 12:08:38,071:INFO:Copying training dataset
2023-04-29 12:08:38,123:INFO:Checking base model
2023-04-29 12:08:38,123:INFO:Base model : Logistic Regression
2023-04-29 12:08:38,123:INFO:Declaring metric variables
2023-04-29 12:08:38,123:INFO:Defining Hyperparameters
2023-04-29 12:08:38,176:INFO:Tuning with n_jobs=-1
2023-04-29 12:08:38,177:INFO:Initializing RandomizedSearchCV
2023-04-29 12:08:40,129:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:40,333:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:40,514:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:40,909:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:41,262:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:41,443:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:41,744:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:42,209:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:42,392:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:42,630:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:43,037:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:43,328:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:43,629:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:43,865:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:44,022:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:44,540:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:44,671:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:44,874:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:45,353:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:45,527:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:45,740:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:45,906:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:46,301:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:46,337:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:46,766:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:46,988:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:47,170:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:47,570:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:47,775:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:47,831:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:48,234:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:48,491:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:48,685:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:48,834:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:49,269:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:49,406:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:49,766:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:49,939:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:50,152:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:50,574:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:50,585:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:50,853:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:51,146:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:51,644:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:51,658:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:51,803:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:52,161:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:52,541:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:52,807:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:52,940:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:53,357:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:53,358:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:53,908:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:54,138:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:54,400:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:54,456:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:54,870:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:55,247:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:55,374:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:55,731:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:56,087:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:56,326:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:56,671:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:56,782:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:57,179:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:57,578:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:57,978:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:58,308:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:58,455:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:58,791:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:58,966:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:59,201:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:59,437:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:08:59,865:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:00,080:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:00,234:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:00,528:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:00,696:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:00,997:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:01,411:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:01,571:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:01,861:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:02,187:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:02,342:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:02,756:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:02,926:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:03,328:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:03,431:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:03,755:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:03,942:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:04,342:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:04,352:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:04,819:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:04,936:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:05,145:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:05,430:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:05,510:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:05,740:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:05,853:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:06,104:INFO:best_params: {'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 4.322}
2023-04-29 12:09:06,104:INFO:Hyperparameter search completed
2023-04-29 12:09:06,104:INFO:SubProcess create_model() called ==================================
2023-04-29 12:09:06,105:INFO:Initializing create_model()
2023-04-29 12:09:06,105:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFF962370>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDDA460E20>, model_only=True, return_train_score=False, kwargs={'class_weight': 'balanced', 'C': 4.322})
2023-04-29 12:09:06,105:INFO:Checking exceptions
2023-04-29 12:09:06,105:INFO:Importing libraries
2023-04-29 12:09:06,105:INFO:Copying training dataset
2023-04-29 12:09:06,191:INFO:Defining folds
2023-04-29 12:09:06,191:INFO:Declaring metric variables
2023-04-29 12:09:06,191:INFO:Importing untrained model
2023-04-29 12:09:06,191:INFO:Declaring custom model
2023-04-29 12:09:06,191:INFO:Logistic Regression Imported successfully
2023-04-29 12:09:06,191:INFO:Starting cross validation
2023-04-29 12:09:06,191:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 12:09:08,427:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:08,435:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:08,620:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:08,633:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:08,833:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:08,848:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:08,941:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:08,949:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:09,195:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:09,203:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:09,384:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:09,392:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:09,555:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:09,563:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:09,667:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:09,675:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:09,757:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:09,765:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:09,921:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:09,928:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:10,255:INFO:Calculating mean and std
2023-04-29 12:09:10,255:INFO:Creating metrics dataframe
2023-04-29 12:09:10,257:INFO:Finalizing model
2023-04-29 12:09:11,762:INFO:Uploading results into container
2023-04-29 12:09:11,763:INFO:Uploading model into container now
2023-04-29 12:09:11,763:INFO:_master_model_container: 15
2023-04-29 12:09:11,763:INFO:_display_container: 3
2023-04-29 12:09:11,763:INFO:LogisticRegression(C=4.322, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-29 12:09:11,763:INFO:create_model() successfully completed......................................
2023-04-29 12:09:11,814:INFO:SubProcess create_model() end ==================================
2023-04-29 12:09:11,814:INFO:choose_better activated
2023-04-29 12:09:11,814:INFO:SubProcess create_model() called ==================================
2023-04-29 12:09:11,814:INFO:Initializing create_model()
2023-04-29 12:09:11,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFF962370>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:09:11,814:INFO:Checking exceptions
2023-04-29 12:09:11,815:INFO:Importing libraries
2023-04-29 12:09:11,815:INFO:Copying training dataset
2023-04-29 12:09:11,903:INFO:Defining folds
2023-04-29 12:09:11,904:INFO:Declaring metric variables
2023-04-29 12:09:11,904:INFO:Importing untrained model
2023-04-29 12:09:11,904:INFO:Declaring custom model
2023-04-29 12:09:11,904:INFO:Logistic Regression Imported successfully
2023-04-29 12:09:11,904:INFO:Starting cross validation
2023-04-29 12:09:11,905:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-29 12:09:14,071:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:14,079:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:14,325:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:14,341:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:14,606:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:14,613:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:14,717:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:14,725:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:14,814:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:14,821:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:15,004:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:15,012:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:15,172:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:15,179:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:15,282:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:15,289:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:15,450:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:15,458:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:15,571:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:15,579:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(accuracy_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\utils\_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:15,903:INFO:Calculating mean and std
2023-04-29 12:09:15,903:INFO:Creating metrics dataframe
2023-04-29 12:09:15,904:INFO:Finalizing model
2023-04-29 12:09:17,448:INFO:Uploading results into container
2023-04-29 12:09:17,449:INFO:Uploading model into container now
2023-04-29 12:09:17,449:INFO:_master_model_container: 16
2023-04-29 12:09:17,449:INFO:_display_container: 4
2023-04-29 12:09:17,449:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-29 12:09:17,449:INFO:create_model() successfully completed......................................
2023-04-29 12:09:17,496:INFO:SubProcess create_model() end ==================================
2023-04-29 12:09:17,496:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for F1_score is 0.0
2023-04-29 12:09:17,496:INFO:LogisticRegression(C=4.322, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for F1_score is 0.0
2023-04-29 12:09:17,497:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2023-04-29 12:09:17,497:INFO:choose_better completed
2023-04-29 12:09:17,497:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-29 12:09:17,502:INFO:_master_model_container: 16
2023-04-29 12:09:17,502:INFO:_display_container: 3
2023-04-29 12:09:17,502:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-29 12:09:17,502:INFO:tune_model() successfully completed......................................
2023-04-29 12:09:17,572:INFO:Initializing tune_model()
2023-04-29 12:09:17,572:INFO:tune_model(estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=f1_score, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFF962370>)
2023-04-29 12:09:17,572:INFO:Checking exceptions
2023-04-29 12:09:17,607:INFO:Copying training dataset
2023-04-29 12:09:17,657:INFO:Checking base model
2023-04-29 12:09:17,657:INFO:Base model : K Neighbors Classifier
2023-04-29 12:09:17,657:INFO:Declaring metric variables
2023-04-29 12:09:17,657:INFO:Defining Hyperparameters
2023-04-29 12:09:17,702:INFO:Tuning with n_jobs=-1
2023-04-29 12:09:17,702:INFO:Initializing RandomizedSearchCV
2023-04-29 12:09:40,570:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:41,682:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:41,772:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:42,211:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:42,240:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:09:42,480:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:10:01,206:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:10:02,515:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:10:02,684:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:10:02,971:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:10:03,143:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:10:03,521:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:10:13,906:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:10:14,759:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:10:14,893:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:10:14,903:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:10:15,259:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:10:15,456:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:10:16,023:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:10:16,124:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:10:16,462:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:10:16,558:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(f1_score, needs_proba=True, error_score=0.0)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\metrics\_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous targets

  warnings.warn(

2023-04-29 12:10:27,083:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:27,083:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:27,083:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:27,083:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:27,449:INFO:Soft dependency imported: prophet: 1.1.2
2023-04-29 12:10:35,116:INFO:PyCaret ClassificationExperiment
2023-04-29 12:10:35,116:INFO:Logging name: clf-default-name
2023-04-29 12:10:35,116:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-29 12:10:35,116:INFO:version 3.0.0
2023-04-29 12:10:35,116:INFO:Initializing setup()
2023-04-29 12:10:35,116:INFO:self.USI: eaa5
2023-04-29 12:10:35,116:INFO:self._variable_keys: {'y_train', 'X_test', 'data', 'target_param', 'USI', 'exp_id', 'fold_groups_param', 'fix_imbalance', 'exp_name_log', 'gpu_param', 'y_test', 'logging_param', 'fold_generator', 'X', '_available_plots', 'seed', 'fold_shuffle_param', 'memory', 'n_jobs_param', 'X_train', 'log_plots_param', 'idx', 'pipeline', 'y', '_ml_usecase', 'html_param', 'is_multiclass', 'gpu_n_jobs_param'}
2023-04-29 12:10:35,116:INFO:Checking environment
2023-04-29 12:10:35,116:INFO:python_version: 3.9.12
2023-04-29 12:10:35,116:INFO:python_build: ('main', 'Apr  4 2022 05:22:27')
2023-04-29 12:10:35,116:INFO:machine: AMD64
2023-04-29 12:10:35,124:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-29 12:10:35,126:INFO:Memory: svmem(total=67772514304, available=57674420224, percent=14.9, used=10098094080, free=57674420224)
2023-04-29 12:10:35,126:INFO:Physical Core: 8
2023-04-29 12:10:35,126:INFO:Logical Core: 16
2023-04-29 12:10:35,126:INFO:Checking libraries
2023-04-29 12:10:35,126:INFO:System:
2023-04-29 12:10:35,126:INFO:    python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]
2023-04-29 12:10:35,126:INFO:executable: C:\Users\Administrator\anaconda3\envs\tf274gpu\python.exe
2023-04-29 12:10:35,126:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-29 12:10:35,126:INFO:PyCaret required dependencies:
2023-04-29 12:10:35,126:INFO:                 pip: 21.2.4
2023-04-29 12:10:35,126:INFO:          setuptools: 61.2.0
2023-04-29 12:10:35,126:INFO:             pycaret: 3.0.0
2023-04-29 12:10:35,126:INFO:             IPython: 7.34.0
2023-04-29 12:10:35,126:INFO:          ipywidgets: 7.6.5
2023-04-29 12:10:35,126:INFO:                tqdm: 4.64.0
2023-04-29 12:10:35,126:INFO:               numpy: 1.21.6
2023-04-29 12:10:35,126:INFO:              pandas: 1.5.3
2023-04-29 12:10:35,126:INFO:              jinja2: 3.1.2
2023-04-29 12:10:35,127:INFO:               scipy: 1.9.1
2023-04-29 12:10:35,127:INFO:              joblib: 1.2.0
2023-04-29 12:10:35,127:INFO:             sklearn: 1.2.2
2023-04-29 12:10:35,127:INFO:                pyod: 1.0.9
2023-04-29 12:10:35,127:INFO:            imblearn: 0.10.1
2023-04-29 12:10:35,127:INFO:   category_encoders: 2.6.0
2023-04-29 12:10:35,127:INFO:            lightgbm: 3.3.5
2023-04-29 12:10:35,127:INFO:               numba: 0.55.1
2023-04-29 12:10:35,127:INFO:            requests: 2.27.1
2023-04-29 12:10:35,127:INFO:          matplotlib: 3.5.1
2023-04-29 12:10:35,127:INFO:          scikitplot: 0.3.7
2023-04-29 12:10:35,127:INFO:         yellowbrick: 1.5
2023-04-29 12:10:35,127:INFO:              plotly: 5.14.1
2023-04-29 12:10:35,127:INFO:             kaleido: 0.2.1
2023-04-29 12:10:35,127:INFO:         statsmodels: 0.13.2
2023-04-29 12:10:35,127:INFO:              sktime: 0.17.2
2023-04-29 12:10:35,127:INFO:               tbats: 1.1.3
2023-04-29 12:10:35,127:INFO:            pmdarima: 2.0.3
2023-04-29 12:10:35,127:INFO:              psutil: 5.9.5
2023-04-29 12:10:35,127:INFO:PyCaret optional dependencies:
2023-04-29 12:10:35,132:INFO:                shap: Not installed
2023-04-29 12:10:35,132:INFO:           interpret: Not installed
2023-04-29 12:10:35,132:INFO:                umap: Not installed
2023-04-29 12:10:35,132:INFO:    pandas_profiling: Not installed
2023-04-29 12:10:35,132:INFO:  explainerdashboard: Not installed
2023-04-29 12:10:35,132:INFO:             autoviz: Not installed
2023-04-29 12:10:35,132:INFO:           fairlearn: Not installed
2023-04-29 12:10:35,132:INFO:             xgboost: 1.7.5
2023-04-29 12:10:35,132:INFO:            catboost: 1.1.1
2023-04-29 12:10:35,132:INFO:              kmodes: Not installed
2023-04-29 12:10:35,132:INFO:             mlxtend: Not installed
2023-04-29 12:10:35,132:INFO:       statsforecast: Not installed
2023-04-29 12:10:35,132:INFO:        tune_sklearn: Not installed
2023-04-29 12:10:35,132:INFO:                 ray: Not installed
2023-04-29 12:10:35,132:INFO:            hyperopt: Not installed
2023-04-29 12:10:35,132:INFO:              optuna: 3.1.1
2023-04-29 12:10:35,132:INFO:               skopt: Not installed
2023-04-29 12:10:35,132:INFO:              mlflow: Not installed
2023-04-29 12:10:35,132:INFO:              gradio: Not installed
2023-04-29 12:10:35,132:INFO:             fastapi: Not installed
2023-04-29 12:10:35,132:INFO:             uvicorn: Not installed
2023-04-29 12:10:35,132:INFO:              m2cgen: Not installed
2023-04-29 12:10:35,132:INFO:           evidently: Not installed
2023-04-29 12:10:35,132:INFO:               fugue: Not installed
2023-04-29 12:10:35,132:INFO:           streamlit: Not installed
2023-04-29 12:10:35,132:INFO:             prophet: 1.1.2
2023-04-29 12:10:35,132:INFO:None
2023-04-29 12:10:35,132:INFO:Set up GPU usage.
2023-04-29 12:10:35,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,132:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0
2023-04-29 12:10:35,132:INFO:Set up data.
2023-04-29 12:10:35,211:INFO:Set up train/test split.
2023-04-29 12:10:35,336:INFO:Set up index.
2023-04-29 12:10:35,337:INFO:Set up folding strategy.
2023-04-29 12:10:35,337:INFO:Assigning column types.
2023-04-29 12:10:35,356:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 12:10:35,356:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,380:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 12:10:35,380:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,381:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,381:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 12:10:35,381:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,399:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 12:10:35,427:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 12:10:35,441:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,479:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 12:10:35,479:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,479:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,480:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 12:10:35,480:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,498:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,502:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,503:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 12:10:35,509:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 12:10:35,509:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 12:10:35,509:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,550:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,551:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,551:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 12:10:35,551:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,572:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,576:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,577:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 12:10:35,582:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 12:10:35,583:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,622:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,622:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,622:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 12:10:35,622:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,641:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,645:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,646:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 12:10:35,652:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 12:10:35,652:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-29 12:10:35,652:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,690:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,690:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,691:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,710:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,713:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,714:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 12:10:35,720:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 12:10:35,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,759:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,759:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,759:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,778:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,782:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:35,783:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 12:10:35,788:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 12:10:35,790:INFO:Preparing preprocessing pipeline...
2023-04-29 12:10:35,796:INFO:Set up label encoding.
2023-04-29 12:10:35,796:INFO:Set up simple imputation.
2023-04-29 12:10:35,796:INFO:Set up feature normalization.
2023-04-29 12:10:35,799:INFO:Set up column name cleaning.
2023-04-29 12:10:37,520:INFO:Finished creating preprocessing pipeline.
2023-04-29 12:10:37,523:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Month', 'Day_of_Month',
                                             'Estimated_Departure_Time',
                                             'Estimated_Arrival_Time',
                                             'Cancelled', 'Diverted'...
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-04-29 12:10:37,524:INFO:Creating final display dataframe.
2023-04-29 12:10:39,565:INFO:Setup _display_container:                     Description                       Value
0                    Session id                        8245
1                        Target                       Delay
2                   Target type                      Binary
3                Target mapping  Delayed: 0, Not_Delayed: 1
4           Original data shape                (255001, 18)
5        Transformed data shape                (255001, 18)
6   Transformed train set shape                (204000, 18)
7    Transformed test set shape                 (51001, 18)
8              Numeric features                          17
9                    Preprocess                        True
10              Imputation type                      simple
11           Numeric imputation                        mean
12       Categorical imputation                        mode
13                    Normalize                        True
14             Normalize method                      zscore
15               Fold Generator             StratifiedKFold
16                  Fold Number                          10
17                     CPU Jobs                          -1
18                      Use GPU                        True
19               Log Experiment                       False
20              Experiment Name            clf-default-name
21                          USI                        eaa5
2023-04-29 12:10:39,568:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:39,592:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:39,592:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:39,592:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:39,604:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:39,607:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:39,607:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 12:10:39,613:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 12:10:39,613:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:39,651:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:39,651:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:39,653:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:39,672:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:39,675:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:10:39,676:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 12:10:39,682:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 12:10:39,683:INFO:setup() successfully completed in 4.6s...............
2023-04-29 12:10:39,684:INFO:Initializing compare_models()
2023-04-29 12:10:39,684:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F87F2D2430>, include=None, fold=5, round=4, cross_validation=True, sort=f1_score, n_select=2, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001F87F2D2430>, 'include': None, 'exclude': ['svm', 'ridge'], 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'f1_score', 'n_select': 2, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['svm', 'ridge'])
2023-04-29 12:10:39,684:INFO:Checking exceptions
2023-04-29 12:10:39,741:INFO:Preparing display monitor
2023-04-29 12:10:39,744:INFO:Initializing Logistic Regression
2023-04-29 12:10:39,744:INFO:Total runtime is 0.0 minutes
2023-04-29 12:10:39,744:INFO:SubProcess create_model() called ==================================
2023-04-29 12:10:39,744:INFO:Initializing create_model()
2023-04-29 12:10:39,744:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F87F2D2430>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F84EEF1E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:10:39,744:INFO:Checking exceptions
2023-04-29 12:10:39,744:INFO:Importing libraries
2023-04-29 12:10:39,744:INFO:Copying training dataset
2023-04-29 12:10:39,833:INFO:Defining folds
2023-04-29 12:10:39,833:INFO:Declaring metric variables
2023-04-29 12:10:39,833:INFO:Importing untrained model
2023-04-29 12:10:39,833:INFO:Logistic Regression Imported successfully
2023-04-29 12:10:39,834:INFO:Starting cross validation
2023-04-29 12:10:39,834:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-04-29 12:10:51,767:INFO:Calculating mean and std
2023-04-29 12:10:51,768:INFO:Creating metrics dataframe
2023-04-29 12:10:51,802:INFO:Uploading results into container
2023-04-29 12:10:51,802:INFO:Uploading model into container now
2023-04-29 12:10:51,802:INFO:_master_model_container: 1
2023-04-29 12:10:51,802:INFO:_display_container: 2
2023-04-29 12:10:51,802:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-29 12:10:51,803:INFO:create_model() successfully completed......................................
2023-04-29 12:10:51,863:INFO:SubProcess create_model() end ==================================
2023-04-29 12:10:51,863:INFO:Creating metrics dataframe
2023-04-29 12:10:51,865:INFO:Initializing K Neighbors Classifier
2023-04-29 12:10:51,865:INFO:Total runtime is 0.20201817750930787 minutes
2023-04-29 12:10:51,865:INFO:SubProcess create_model() called ==================================
2023-04-29 12:10:51,866:INFO:Initializing create_model()
2023-04-29 12:10:51,866:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F87F2D2430>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F84EEF1E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:10:51,866:INFO:Checking exceptions
2023-04-29 12:10:51,866:INFO:Importing libraries
2023-04-29 12:10:51,866:INFO:Copying training dataset
2023-04-29 12:10:51,947:INFO:Defining folds
2023-04-29 12:10:51,947:INFO:Declaring metric variables
2023-04-29 12:10:51,947:INFO:Importing untrained model
2023-04-29 12:10:51,947:INFO:K Neighbors Classifier Imported successfully
2023-04-29 12:10:51,947:INFO:Starting cross validation
2023-04-29 12:10:51,948:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-04-29 12:11:27,369:INFO:Calculating mean and std
2023-04-29 12:11:27,370:INFO:Creating metrics dataframe
2023-04-29 12:11:27,403:INFO:Uploading results into container
2023-04-29 12:11:27,403:INFO:Uploading model into container now
2023-04-29 12:11:27,403:INFO:_master_model_container: 2
2023-04-29 12:11:27,403:INFO:_display_container: 2
2023-04-29 12:11:27,404:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-29 12:11:27,404:INFO:create_model() successfully completed......................................
2023-04-29 12:11:27,458:INFO:SubProcess create_model() end ==================================
2023-04-29 12:11:27,458:INFO:Creating metrics dataframe
2023-04-29 12:11:27,461:INFO:Initializing Naive Bayes
2023-04-29 12:11:27,461:INFO:Total runtime is 0.7952962716420491 minutes
2023-04-29 12:11:27,461:INFO:SubProcess create_model() called ==================================
2023-04-29 12:11:27,461:INFO:Initializing create_model()
2023-04-29 12:11:27,461:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F87F2D2430>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F84EEF1E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:11:27,461:INFO:Checking exceptions
2023-04-29 12:11:27,461:INFO:Importing libraries
2023-04-29 12:11:27,461:INFO:Copying training dataset
2023-04-29 12:11:27,543:INFO:Defining folds
2023-04-29 12:11:27,543:INFO:Declaring metric variables
2023-04-29 12:11:27,543:INFO:Importing untrained model
2023-04-29 12:11:27,543:INFO:Naive Bayes Imported successfully
2023-04-29 12:11:27,543:INFO:Starting cross validation
2023-04-29 12:11:27,544:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-04-29 12:11:38,968:INFO:Calculating mean and std
2023-04-29 12:11:38,969:INFO:Creating metrics dataframe
2023-04-29 12:11:39,001:INFO:Uploading results into container
2023-04-29 12:11:39,001:INFO:Uploading model into container now
2023-04-29 12:11:39,001:INFO:_master_model_container: 3
2023-04-29 12:11:39,001:INFO:_display_container: 2
2023-04-29 12:11:39,001:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-29 12:11:39,001:INFO:create_model() successfully completed......................................
2023-04-29 12:11:39,055:INFO:SubProcess create_model() end ==================================
2023-04-29 12:11:39,055:INFO:Creating metrics dataframe
2023-04-29 12:11:39,057:INFO:Initializing Decision Tree Classifier
2023-04-29 12:11:39,057:INFO:Total runtime is 0.9885553320248921 minutes
2023-04-29 12:11:39,058:INFO:SubProcess create_model() called ==================================
2023-04-29 12:11:39,058:INFO:Initializing create_model()
2023-04-29 12:11:39,058:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F87F2D2430>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F84EEF1E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:11:39,058:INFO:Checking exceptions
2023-04-29 12:11:39,058:INFO:Importing libraries
2023-04-29 12:11:39,058:INFO:Copying training dataset
2023-04-29 12:11:39,138:INFO:Defining folds
2023-04-29 12:11:39,138:INFO:Declaring metric variables
2023-04-29 12:11:39,138:INFO:Importing untrained model
2023-04-29 12:11:39,138:INFO:Decision Tree Classifier Imported successfully
2023-04-29 12:11:39,138:INFO:Starting cross validation
2023-04-29 12:11:39,139:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-04-29 12:11:58,584:INFO:Calculating mean and std
2023-04-29 12:11:58,584:INFO:Creating metrics dataframe
2023-04-29 12:11:58,618:INFO:Uploading results into container
2023-04-29 12:11:58,618:INFO:Uploading model into container now
2023-04-29 12:11:58,619:INFO:_master_model_container: 4
2023-04-29 12:11:58,619:INFO:_display_container: 2
2023-04-29 12:11:58,619:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8245, splitter='best')
2023-04-29 12:11:58,619:INFO:create_model() successfully completed......................................
2023-04-29 12:11:58,680:INFO:SubProcess create_model() end ==================================
2023-04-29 12:11:58,680:INFO:Creating metrics dataframe
2023-04-29 12:11:58,682:INFO:Initializing Random Forest Classifier
2023-04-29 12:11:58,682:INFO:Total runtime is 1.3156431237856547 minutes
2023-04-29 12:11:58,682:INFO:SubProcess create_model() called ==================================
2023-04-29 12:11:58,682:INFO:Initializing create_model()
2023-04-29 12:11:58,682:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F87F2D2430>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F84EEF1E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:11:58,682:INFO:Checking exceptions
2023-04-29 12:11:58,682:INFO:Importing libraries
2023-04-29 12:11:58,682:INFO:Copying training dataset
2023-04-29 12:11:58,765:INFO:Defining folds
2023-04-29 12:11:58,765:INFO:Declaring metric variables
2023-04-29 12:11:58,766:INFO:Importing untrained model
2023-04-29 12:11:58,766:INFO:Random Forest Classifier Imported successfully
2023-04-29 12:11:58,766:INFO:Starting cross validation
2023-04-29 12:11:58,766:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-04-29 12:12:28,806:INFO:Calculating mean and std
2023-04-29 12:12:28,806:INFO:Creating metrics dataframe
2023-04-29 12:12:28,840:INFO:Uploading results into container
2023-04-29 12:12:28,840:INFO:Uploading model into container now
2023-04-29 12:12:28,840:INFO:_master_model_container: 5
2023-04-29 12:12:28,840:INFO:_display_container: 2
2023-04-29 12:12:28,840:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8245, verbose=0, warm_start=False)
2023-04-29 12:12:28,840:INFO:create_model() successfully completed......................................
2023-04-29 12:12:28,906:INFO:SubProcess create_model() end ==================================
2023-04-29 12:12:28,906:INFO:Creating metrics dataframe
2023-04-29 12:12:28,908:INFO:Initializing Quadratic Discriminant Analysis
2023-04-29 12:12:28,908:INFO:Total runtime is 1.8194026827812195 minutes
2023-04-29 12:12:28,908:INFO:SubProcess create_model() called ==================================
2023-04-29 12:12:28,908:INFO:Initializing create_model()
2023-04-29 12:12:28,908:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F87F2D2430>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F84EEF1E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:12:28,908:INFO:Checking exceptions
2023-04-29 12:12:28,908:INFO:Importing libraries
2023-04-29 12:12:28,908:INFO:Copying training dataset
2023-04-29 12:12:28,988:INFO:Defining folds
2023-04-29 12:12:28,988:INFO:Declaring metric variables
2023-04-29 12:12:28,988:INFO:Importing untrained model
2023-04-29 12:12:28,989:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-29 12:12:28,989:INFO:Starting cross validation
2023-04-29 12:12:28,989:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-04-29 12:12:40,788:INFO:Calculating mean and std
2023-04-29 12:12:40,789:INFO:Creating metrics dataframe
2023-04-29 12:12:40,822:INFO:Uploading results into container
2023-04-29 12:12:40,822:INFO:Uploading model into container now
2023-04-29 12:12:40,822:INFO:_master_model_container: 6
2023-04-29 12:12:40,823:INFO:_display_container: 2
2023-04-29 12:12:40,823:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-29 12:12:40,823:INFO:create_model() successfully completed......................................
2023-04-29 12:12:40,880:INFO:SubProcess create_model() end ==================================
2023-04-29 12:12:40,880:INFO:Creating metrics dataframe
2023-04-29 12:12:40,882:INFO:Initializing Ada Boost Classifier
2023-04-29 12:12:40,882:INFO:Total runtime is 2.0189738432566324 minutes
2023-04-29 12:12:40,882:INFO:SubProcess create_model() called ==================================
2023-04-29 12:12:40,882:INFO:Initializing create_model()
2023-04-29 12:12:40,882:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F87F2D2430>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F84EEF1E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:12:40,882:INFO:Checking exceptions
2023-04-29 12:12:40,882:INFO:Importing libraries
2023-04-29 12:12:40,882:INFO:Copying training dataset
2023-04-29 12:12:40,962:INFO:Defining folds
2023-04-29 12:12:40,962:INFO:Declaring metric variables
2023-04-29 12:12:40,962:INFO:Importing untrained model
2023-04-29 12:12:40,963:INFO:Ada Boost Classifier Imported successfully
2023-04-29 12:12:40,963:INFO:Starting cross validation
2023-04-29 12:12:40,963:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-04-29 12:12:59,164:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:12:59,164:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:12:59,164:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:12:59,164:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:12:59,523:INFO:Soft dependency imported: prophet: 1.1.2
2023-04-29 12:13:07,090:INFO:PyCaret ClassificationExperiment
2023-04-29 12:13:07,090:INFO:Logging name: clf-default-name
2023-04-29 12:13:07,090:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-29 12:13:07,090:INFO:version 3.0.0
2023-04-29 12:13:07,090:INFO:Initializing setup()
2023-04-29 12:13:07,090:INFO:self.USI: 4ed6
2023-04-29 12:13:07,090:INFO:self._variable_keys: {'n_jobs_param', 'X', 'fix_imbalance', 'gpu_n_jobs_param', 'seed', '_ml_usecase', 'y_test', 'log_plots_param', 'X_train', 'is_multiclass', 'html_param', '_available_plots', 'fold_groups_param', 'logging_param', 'gpu_param', 'exp_id', 'fold_shuffle_param', 'pipeline', 'data', 'memory', 'target_param', 'fold_generator', 'exp_name_log', 'X_test', 'y_train', 'USI', 'idx', 'y'}
2023-04-29 12:13:07,090:INFO:Checking environment
2023-04-29 12:13:07,090:INFO:python_version: 3.9.12
2023-04-29 12:13:07,090:INFO:python_build: ('main', 'Apr  4 2022 05:22:27')
2023-04-29 12:13:07,091:INFO:machine: AMD64
2023-04-29 12:13:07,098:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-29 12:13:07,100:INFO:Memory: svmem(total=67772514304, available=57498030080, percent=15.2, used=10274484224, free=57498030080)
2023-04-29 12:13:07,100:INFO:Physical Core: 8
2023-04-29 12:13:07,100:INFO:Logical Core: 16
2023-04-29 12:13:07,100:INFO:Checking libraries
2023-04-29 12:13:07,100:INFO:System:
2023-04-29 12:13:07,101:INFO:    python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]
2023-04-29 12:13:07,101:INFO:executable: C:\Users\Administrator\anaconda3\envs\tf274gpu\python.exe
2023-04-29 12:13:07,101:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-29 12:13:07,101:INFO:PyCaret required dependencies:
2023-04-29 12:13:07,101:INFO:                 pip: 21.2.4
2023-04-29 12:13:07,101:INFO:          setuptools: 61.2.0
2023-04-29 12:13:07,101:INFO:             pycaret: 3.0.0
2023-04-29 12:13:07,101:INFO:             IPython: 7.34.0
2023-04-29 12:13:07,101:INFO:          ipywidgets: 7.6.5
2023-04-29 12:13:07,101:INFO:                tqdm: 4.64.0
2023-04-29 12:13:07,101:INFO:               numpy: 1.21.6
2023-04-29 12:13:07,101:INFO:              pandas: 1.5.3
2023-04-29 12:13:07,101:INFO:              jinja2: 3.1.2
2023-04-29 12:13:07,101:INFO:               scipy: 1.9.1
2023-04-29 12:13:07,101:INFO:              joblib: 1.2.0
2023-04-29 12:13:07,101:INFO:             sklearn: 1.2.2
2023-04-29 12:13:07,101:INFO:                pyod: 1.0.9
2023-04-29 12:13:07,101:INFO:            imblearn: 0.10.1
2023-04-29 12:13:07,101:INFO:   category_encoders: 2.6.0
2023-04-29 12:13:07,101:INFO:            lightgbm: 3.3.5
2023-04-29 12:13:07,101:INFO:               numba: 0.55.1
2023-04-29 12:13:07,101:INFO:            requests: 2.27.1
2023-04-29 12:13:07,101:INFO:          matplotlib: 3.5.1
2023-04-29 12:13:07,101:INFO:          scikitplot: 0.3.7
2023-04-29 12:13:07,101:INFO:         yellowbrick: 1.5
2023-04-29 12:13:07,101:INFO:              plotly: 5.14.1
2023-04-29 12:13:07,101:INFO:             kaleido: 0.2.1
2023-04-29 12:13:07,102:INFO:         statsmodels: 0.13.2
2023-04-29 12:13:07,102:INFO:              sktime: 0.17.2
2023-04-29 12:13:07,102:INFO:               tbats: 1.1.3
2023-04-29 12:13:07,102:INFO:            pmdarima: 2.0.3
2023-04-29 12:13:07,102:INFO:              psutil: 5.9.5
2023-04-29 12:13:07,102:INFO:PyCaret optional dependencies:
2023-04-29 12:13:07,106:INFO:                shap: Not installed
2023-04-29 12:13:07,106:INFO:           interpret: Not installed
2023-04-29 12:13:07,106:INFO:                umap: Not installed
2023-04-29 12:13:07,106:INFO:    pandas_profiling: Not installed
2023-04-29 12:13:07,106:INFO:  explainerdashboard: Not installed
2023-04-29 12:13:07,106:INFO:             autoviz: Not installed
2023-04-29 12:13:07,106:INFO:           fairlearn: Not installed
2023-04-29 12:13:07,106:INFO:             xgboost: 1.7.5
2023-04-29 12:13:07,106:INFO:            catboost: 1.1.1
2023-04-29 12:13:07,106:INFO:              kmodes: Not installed
2023-04-29 12:13:07,106:INFO:             mlxtend: Not installed
2023-04-29 12:13:07,106:INFO:       statsforecast: Not installed
2023-04-29 12:13:07,106:INFO:        tune_sklearn: Not installed
2023-04-29 12:13:07,106:INFO:                 ray: Not installed
2023-04-29 12:13:07,106:INFO:            hyperopt: Not installed
2023-04-29 12:13:07,106:INFO:              optuna: 3.1.1
2023-04-29 12:13:07,106:INFO:               skopt: Not installed
2023-04-29 12:13:07,107:INFO:              mlflow: Not installed
2023-04-29 12:13:07,107:INFO:              gradio: Not installed
2023-04-29 12:13:07,107:INFO:             fastapi: Not installed
2023-04-29 12:13:07,107:INFO:             uvicorn: Not installed
2023-04-29 12:13:07,107:INFO:              m2cgen: Not installed
2023-04-29 12:13:07,107:INFO:           evidently: Not installed
2023-04-29 12:13:07,107:INFO:               fugue: Not installed
2023-04-29 12:13:07,107:INFO:           streamlit: Not installed
2023-04-29 12:13:07,107:INFO:             prophet: 1.1.2
2023-04-29 12:13:07,107:INFO:None
2023-04-29 12:13:07,107:INFO:Set up GPU usage.
2023-04-29 12:13:07,107:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,107:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0
2023-04-29 12:13:07,107:INFO:Set up data.
2023-04-29 12:13:07,180:INFO:Set up train/test split.
2023-04-29 12:13:07,306:INFO:Set up index.
2023-04-29 12:13:07,308:INFO:Set up folding strategy.
2023-04-29 12:13:07,308:INFO:Assigning column types.
2023-04-29 12:13:07,327:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-29 12:13:07,327:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,351:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 12:13:07,351:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,352:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,352:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 12:13:07,352:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,367:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,369:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,370:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 12:13:07,396:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 12:13:07,410:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,447:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-29 12:13:07,447:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,447:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,448:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 12:13:07,448:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,467:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,471:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,472:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 12:13:07,477:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 12:13:07,478:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-29 12:13:07,478:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,516:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,516:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,516:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 12:13:07,516:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,535:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,539:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,540:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 12:13:07,545:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 12:13:07,546:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,584:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,584:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,584:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-29 12:13:07,584:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,603:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,607:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,608:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 12:13:07,613:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 12:13:07,614:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-29 12:13:07,614:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,653:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,653:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,653:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,673:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,677:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,677:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 12:13:07,684:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 12:13:07,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,724:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,724:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,724:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,743:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,747:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:07,748:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 12:13:07,754:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 12:13:07,756:INFO:Preparing preprocessing pipeline...
2023-04-29 12:13:07,761:INFO:Set up label encoding.
2023-04-29 12:13:07,761:INFO:Set up simple imputation.
2023-04-29 12:13:07,761:INFO:Set up feature normalization.
2023-04-29 12:13:07,764:INFO:Set up column name cleaning.
2023-04-29 12:13:09,375:INFO:Finished creating preprocessing pipeline.
2023-04-29 12:13:09,378:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Month', 'Day_of_Month',
                                             'Estimated_Departure_Time',
                                             'Estimated_Arrival_Time',
                                             'Cancelled', 'Diverted'...
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-04-29 12:13:09,378:INFO:Creating final display dataframe.
2023-04-29 12:13:10,105:INFO:Setup _display_container:                     Description                       Value
0                    Session id                        8245
1                        Target                       Delay
2                   Target type                      Binary
3                Target mapping  Delayed: 0, Not_Delayed: 1
4           Original data shape                (255001, 18)
5        Transformed data shape                (255001, 18)
6   Transformed train set shape                (204000, 18)
7    Transformed test set shape                 (51001, 18)
8              Numeric features                          17
9                    Preprocess                        True
10              Imputation type                      simple
11           Numeric imputation                        mean
12       Categorical imputation                        mode
13                    Normalize                        True
14             Normalize method                      zscore
15               Fold Generator             StratifiedKFold
16                  Fold Number                          10
17                     CPU Jobs                          -1
18                      Use GPU                        True
19               Log Experiment                       False
20              Experiment Name            clf-default-name
21                          USI                        4ed6
2023-04-29 12:13:10,109:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:10,133:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:10,133:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:10,133:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:10,147:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:10,149:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:10,150:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 12:13:10,155:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 12:13:10,156:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:10,194:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:10,194:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:10,194:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:10,213:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:10,217:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-29 12:13:10,218:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-29 12:13:10,225:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-29 12:13:10,225:INFO:setup() successfully completed in 3.17s...............
2023-04-29 12:13:10,226:INFO:Initializing compare_models()
2023-04-29 12:13:10,226:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458EE2460>, include=None, fold=5, round=4, cross_validation=True, sort=log_loss, n_select=2, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021458EE2460>, 'include': None, 'exclude': ['svm', 'ridge'], 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'log_loss', 'n_select': 2, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['svm', 'ridge'])
2023-04-29 12:13:10,226:INFO:Checking exceptions
2023-04-29 12:13:10,284:INFO:Preparing display monitor
2023-04-29 12:13:10,286:INFO:Initializing Logistic Regression
2023-04-29 12:13:10,287:INFO:Total runtime is 1.6641616821289062e-05 minutes
2023-04-29 12:13:10,287:INFO:SubProcess create_model() called ==================================
2023-04-29 12:13:10,287:INFO:Initializing create_model()
2023-04-29 12:13:10,287:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458EE2460>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002140CEA98B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:13:10,287:INFO:Checking exceptions
2023-04-29 12:13:10,287:INFO:Importing libraries
2023-04-29 12:13:10,287:INFO:Copying training dataset
2023-04-29 12:13:10,375:INFO:Defining folds
2023-04-29 12:13:10,375:INFO:Declaring metric variables
2023-04-29 12:13:10,375:INFO:Importing untrained model
2023-04-29 12:13:10,375:INFO:Logistic Regression Imported successfully
2023-04-29 12:13:10,376:INFO:Starting cross validation
2023-04-29 12:13:10,376:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-04-29 12:13:22,217:INFO:Calculating mean and std
2023-04-29 12:13:22,218:INFO:Creating metrics dataframe
2023-04-29 12:13:22,253:INFO:Uploading results into container
2023-04-29 12:13:22,254:INFO:Uploading model into container now
2023-04-29 12:13:22,254:INFO:_master_model_container: 1
2023-04-29 12:13:22,254:INFO:_display_container: 2
2023-04-29 12:13:22,254:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8245, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-29 12:13:22,254:INFO:create_model() successfully completed......................................
2023-04-29 12:13:22,310:INFO:SubProcess create_model() end ==================================
2023-04-29 12:13:22,310:INFO:Creating metrics dataframe
2023-04-29 12:13:22,312:INFO:Initializing K Neighbors Classifier
2023-04-29 12:13:22,312:INFO:Total runtime is 0.20041821002960206 minutes
2023-04-29 12:13:22,312:INFO:SubProcess create_model() called ==================================
2023-04-29 12:13:22,313:INFO:Initializing create_model()
2023-04-29 12:13:22,313:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458EE2460>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002140CEA98B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:13:22,313:INFO:Checking exceptions
2023-04-29 12:13:22,313:INFO:Importing libraries
2023-04-29 12:13:22,313:INFO:Copying training dataset
2023-04-29 12:13:22,390:INFO:Defining folds
2023-04-29 12:13:22,390:INFO:Declaring metric variables
2023-04-29 12:13:22,390:INFO:Importing untrained model
2023-04-29 12:13:22,390:INFO:K Neighbors Classifier Imported successfully
2023-04-29 12:13:22,391:INFO:Starting cross validation
2023-04-29 12:13:22,391:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-04-29 12:13:57,431:INFO:Calculating mean and std
2023-04-29 12:13:57,431:INFO:Creating metrics dataframe
2023-04-29 12:13:57,465:INFO:Uploading results into container
2023-04-29 12:13:57,465:INFO:Uploading model into container now
2023-04-29 12:13:57,466:INFO:_master_model_container: 2
2023-04-29 12:13:57,466:INFO:_display_container: 2
2023-04-29 12:13:57,466:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-29 12:13:57,466:INFO:create_model() successfully completed......................................
2023-04-29 12:13:57,521:INFO:SubProcess create_model() end ==================================
2023-04-29 12:13:57,521:INFO:Creating metrics dataframe
2023-04-29 12:13:57,523:INFO:Initializing Naive Bayes
2023-04-29 12:13:57,523:INFO:Total runtime is 0.7872694373130799 minutes
2023-04-29 12:13:57,523:INFO:SubProcess create_model() called ==================================
2023-04-29 12:13:57,523:INFO:Initializing create_model()
2023-04-29 12:13:57,523:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458EE2460>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002140CEA98B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:13:57,523:INFO:Checking exceptions
2023-04-29 12:13:57,523:INFO:Importing libraries
2023-04-29 12:13:57,523:INFO:Copying training dataset
2023-04-29 12:13:57,602:INFO:Defining folds
2023-04-29 12:13:57,602:INFO:Declaring metric variables
2023-04-29 12:13:57,602:INFO:Importing untrained model
2023-04-29 12:13:57,602:INFO:Naive Bayes Imported successfully
2023-04-29 12:13:57,602:INFO:Starting cross validation
2023-04-29 12:13:57,603:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-04-29 12:14:09,135:INFO:Calculating mean and std
2023-04-29 12:14:09,136:INFO:Creating metrics dataframe
2023-04-29 12:14:09,169:INFO:Uploading results into container
2023-04-29 12:14:09,169:INFO:Uploading model into container now
2023-04-29 12:14:09,169:INFO:_master_model_container: 3
2023-04-29 12:14:09,169:INFO:_display_container: 2
2023-04-29 12:14:09,169:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-29 12:14:09,169:INFO:create_model() successfully completed......................................
2023-04-29 12:14:09,224:INFO:SubProcess create_model() end ==================================
2023-04-29 12:14:09,224:INFO:Creating metrics dataframe
2023-04-29 12:14:09,226:INFO:Initializing Decision Tree Classifier
2023-04-29 12:14:09,226:INFO:Total runtime is 0.9823197642962138 minutes
2023-04-29 12:14:09,226:INFO:SubProcess create_model() called ==================================
2023-04-29 12:14:09,226:INFO:Initializing create_model()
2023-04-29 12:14:09,226:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458EE2460>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002140CEA98B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:14:09,227:INFO:Checking exceptions
2023-04-29 12:14:09,227:INFO:Importing libraries
2023-04-29 12:14:09,227:INFO:Copying training dataset
2023-04-29 12:14:09,304:INFO:Defining folds
2023-04-29 12:14:09,304:INFO:Declaring metric variables
2023-04-29 12:14:09,304:INFO:Importing untrained model
2023-04-29 12:14:09,305:INFO:Decision Tree Classifier Imported successfully
2023-04-29 12:14:09,305:INFO:Starting cross validation
2023-04-29 12:14:09,305:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-04-29 12:14:20,780:INFO:Calculating mean and std
2023-04-29 12:14:20,780:INFO:Creating metrics dataframe
2023-04-29 12:14:20,815:INFO:Uploading results into container
2023-04-29 12:14:20,815:INFO:Uploading model into container now
2023-04-29 12:14:20,816:INFO:_master_model_container: 4
2023-04-29 12:14:20,816:INFO:_display_container: 2
2023-04-29 12:14:20,816:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8245, splitter='best')
2023-04-29 12:14:20,816:INFO:create_model() successfully completed......................................
2023-04-29 12:14:20,871:INFO:SubProcess create_model() end ==================================
2023-04-29 12:14:20,871:INFO:Creating metrics dataframe
2023-04-29 12:14:20,873:INFO:Initializing Random Forest Classifier
2023-04-29 12:14:20,874:INFO:Total runtime is 1.17645933230718 minutes
2023-04-29 12:14:20,874:INFO:SubProcess create_model() called ==================================
2023-04-29 12:14:20,874:INFO:Initializing create_model()
2023-04-29 12:14:20,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458EE2460>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002140CEA98B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:14:20,874:INFO:Checking exceptions
2023-04-29 12:14:20,874:INFO:Importing libraries
2023-04-29 12:14:20,874:INFO:Copying training dataset
2023-04-29 12:14:20,953:INFO:Defining folds
2023-04-29 12:14:20,953:INFO:Declaring metric variables
2023-04-29 12:14:20,953:INFO:Importing untrained model
2023-04-29 12:14:20,953:INFO:Random Forest Classifier Imported successfully
2023-04-29 12:14:20,953:INFO:Starting cross validation
2023-04-29 12:14:20,954:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-04-29 12:14:34,743:INFO:Calculating mean and std
2023-04-29 12:14:34,743:INFO:Creating metrics dataframe
2023-04-29 12:14:34,778:INFO:Uploading results into container
2023-04-29 12:14:34,778:INFO:Uploading model into container now
2023-04-29 12:14:34,778:INFO:_master_model_container: 5
2023-04-29 12:14:34,778:INFO:_display_container: 2
2023-04-29 12:14:34,778:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8245, verbose=0, warm_start=False)
2023-04-29 12:14:34,778:INFO:create_model() successfully completed......................................
2023-04-29 12:14:34,834:INFO:SubProcess create_model() end ==================================
2023-04-29 12:14:34,834:INFO:Creating metrics dataframe
2023-04-29 12:14:34,836:INFO:Initializing Quadratic Discriminant Analysis
2023-04-29 12:14:34,836:INFO:Total runtime is 1.409153747558594 minutes
2023-04-29 12:14:34,836:INFO:SubProcess create_model() called ==================================
2023-04-29 12:14:34,836:INFO:Initializing create_model()
2023-04-29 12:14:34,836:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458EE2460>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002140CEA98B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:14:34,836:INFO:Checking exceptions
2023-04-29 12:14:34,836:INFO:Importing libraries
2023-04-29 12:14:34,836:INFO:Copying training dataset
2023-04-29 12:14:34,914:INFO:Defining folds
2023-04-29 12:14:34,915:INFO:Declaring metric variables
2023-04-29 12:14:34,915:INFO:Importing untrained model
2023-04-29 12:14:34,915:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-29 12:14:34,915:INFO:Starting cross validation
2023-04-29 12:14:34,916:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-04-29 12:14:46,561:INFO:Calculating mean and std
2023-04-29 12:14:46,562:INFO:Creating metrics dataframe
2023-04-29 12:14:46,596:INFO:Uploading results into container
2023-04-29 12:14:46,596:INFO:Uploading model into container now
2023-04-29 12:14:46,596:INFO:_master_model_container: 6
2023-04-29 12:14:46,596:INFO:_display_container: 2
2023-04-29 12:14:46,596:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-29 12:14:46,596:INFO:create_model() successfully completed......................................
2023-04-29 12:14:46,653:INFO:SubProcess create_model() end ==================================
2023-04-29 12:14:46,653:INFO:Creating metrics dataframe
2023-04-29 12:14:46,655:INFO:Initializing Ada Boost Classifier
2023-04-29 12:14:46,655:INFO:Total runtime is 1.6061349630355837 minutes
2023-04-29 12:14:46,655:INFO:SubProcess create_model() called ==================================
2023-04-29 12:14:46,655:INFO:Initializing create_model()
2023-04-29 12:14:46,655:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458EE2460>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002140CEA98B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:14:46,655:INFO:Checking exceptions
2023-04-29 12:14:46,656:INFO:Importing libraries
2023-04-29 12:14:46,656:INFO:Copying training dataset
2023-04-29 12:14:46,734:INFO:Defining folds
2023-04-29 12:14:46,734:INFO:Declaring metric variables
2023-04-29 12:14:46,734:INFO:Importing untrained model
2023-04-29 12:14:46,734:INFO:Ada Boost Classifier Imported successfully
2023-04-29 12:14:46,734:INFO:Starting cross validation
2023-04-29 12:14:46,735:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-04-29 12:15:19,097:INFO:Calculating mean and std
2023-04-29 12:15:19,097:INFO:Creating metrics dataframe
2023-04-29 12:15:19,133:INFO:Uploading results into container
2023-04-29 12:15:19,134:INFO:Uploading model into container now
2023-04-29 12:15:19,134:INFO:_master_model_container: 7
2023-04-29 12:15:19,134:INFO:_display_container: 2
2023-04-29 12:15:19,134:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=8245)
2023-04-29 12:15:19,134:INFO:create_model() successfully completed......................................
2023-04-29 12:15:19,187:INFO:SubProcess create_model() end ==================================
2023-04-29 12:15:19,187:INFO:Creating metrics dataframe
2023-04-29 12:15:19,190:INFO:Initializing Gradient Boosting Classifier
2023-04-29 12:15:19,190:INFO:Total runtime is 2.1483925779660544 minutes
2023-04-29 12:15:19,190:INFO:SubProcess create_model() called ==================================
2023-04-29 12:15:19,190:INFO:Initializing create_model()
2023-04-29 12:15:19,190:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458EE2460>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002140CEA98B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:15:19,190:INFO:Checking exceptions
2023-04-29 12:15:19,190:INFO:Importing libraries
2023-04-29 12:15:19,190:INFO:Copying training dataset
2023-04-29 12:15:19,267:INFO:Defining folds
2023-04-29 12:15:19,267:INFO:Declaring metric variables
2023-04-29 12:15:19,267:INFO:Importing untrained model
2023-04-29 12:15:19,268:INFO:Gradient Boosting Classifier Imported successfully
2023-04-29 12:15:19,268:INFO:Starting cross validation
2023-04-29 12:15:19,268:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-04-29 12:17:20,197:INFO:Calculating mean and std
2023-04-29 12:17:20,197:INFO:Creating metrics dataframe
2023-04-29 12:17:20,236:INFO:Uploading results into container
2023-04-29 12:17:20,236:INFO:Uploading model into container now
2023-04-29 12:17:20,236:INFO:_master_model_container: 8
2023-04-29 12:17:20,236:INFO:_display_container: 2
2023-04-29 12:17:20,236:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8245, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-29 12:17:20,236:INFO:create_model() successfully completed......................................
2023-04-29 12:17:20,298:INFO:SubProcess create_model() end ==================================
2023-04-29 12:17:20,298:INFO:Creating metrics dataframe
2023-04-29 12:17:20,300:INFO:Initializing Linear Discriminant Analysis
2023-04-29 12:17:20,300:INFO:Total runtime is 4.1668989062309265 minutes
2023-04-29 12:17:20,300:INFO:SubProcess create_model() called ==================================
2023-04-29 12:17:20,300:INFO:Initializing create_model()
2023-04-29 12:17:20,300:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458EE2460>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002140CEA98B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:17:20,300:INFO:Checking exceptions
2023-04-29 12:17:20,300:INFO:Importing libraries
2023-04-29 12:17:20,301:INFO:Copying training dataset
2023-04-29 12:17:20,385:INFO:Defining folds
2023-04-29 12:17:20,385:INFO:Declaring metric variables
2023-04-29 12:17:20,385:INFO:Importing untrained model
2023-04-29 12:17:20,385:INFO:Linear Discriminant Analysis Imported successfully
2023-04-29 12:17:20,385:INFO:Starting cross validation
2023-04-29 12:17:20,386:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-04-29 12:17:33,267:INFO:Calculating mean and std
2023-04-29 12:17:33,267:INFO:Creating metrics dataframe
2023-04-29 12:17:33,304:INFO:Uploading results into container
2023-04-29 12:17:33,304:INFO:Uploading model into container now
2023-04-29 12:17:33,304:INFO:_master_model_container: 9
2023-04-29 12:17:33,304:INFO:_display_container: 2
2023-04-29 12:17:33,304:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-29 12:17:33,304:INFO:create_model() successfully completed......................................
2023-04-29 12:17:33,359:INFO:SubProcess create_model() end ==================================
2023-04-29 12:17:33,360:INFO:Creating metrics dataframe
2023-04-29 12:17:33,362:INFO:Initializing Extra Trees Classifier
2023-04-29 12:17:33,362:INFO:Total runtime is 4.384595310688018 minutes
2023-04-29 12:17:33,362:INFO:SubProcess create_model() called ==================================
2023-04-29 12:17:33,362:INFO:Initializing create_model()
2023-04-29 12:17:33,362:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458EE2460>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002140CEA98B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:17:33,362:INFO:Checking exceptions
2023-04-29 12:17:33,362:INFO:Importing libraries
2023-04-29 12:17:33,362:INFO:Copying training dataset
2023-04-29 12:17:33,442:INFO:Defining folds
2023-04-29 12:17:33,442:INFO:Declaring metric variables
2023-04-29 12:17:33,442:INFO:Importing untrained model
2023-04-29 12:17:33,442:INFO:Extra Trees Classifier Imported successfully
2023-04-29 12:17:33,442:INFO:Starting cross validation
2023-04-29 12:17:33,443:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-04-29 12:17:58,829:INFO:Calculating mean and std
2023-04-29 12:17:58,830:INFO:Creating metrics dataframe
2023-04-29 12:17:58,864:INFO:Uploading results into container
2023-04-29 12:17:58,865:INFO:Uploading model into container now
2023-04-29 12:17:58,865:INFO:_master_model_container: 10
2023-04-29 12:17:58,865:INFO:_display_container: 2
2023-04-29 12:17:58,865:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=8245, verbose=0, warm_start=False)
2023-04-29 12:17:58,865:INFO:create_model() successfully completed......................................
2023-04-29 12:17:58,930:INFO:SubProcess create_model() end ==================================
2023-04-29 12:17:58,930:INFO:Creating metrics dataframe
2023-04-29 12:17:58,933:INFO:Initializing Extreme Gradient Boosting
2023-04-29 12:17:58,933:INFO:Total runtime is 4.810780743757883 minutes
2023-04-29 12:17:58,933:INFO:SubProcess create_model() called ==================================
2023-04-29 12:17:58,933:INFO:Initializing create_model()
2023-04-29 12:17:58,933:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458EE2460>, estimator=xgboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002140CEA98B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:17:58,933:INFO:Checking exceptions
2023-04-29 12:17:58,933:INFO:Importing libraries
2023-04-29 12:17:58,933:INFO:Copying training dataset
2023-04-29 12:17:59,013:INFO:Defining folds
2023-04-29 12:17:59,013:INFO:Declaring metric variables
2023-04-29 12:17:59,013:INFO:Importing untrained model
2023-04-29 12:17:59,013:INFO:Extreme Gradient Boosting Imported successfully
2023-04-29 12:17:59,013:INFO:Starting cross validation
2023-04-29 12:17:59,014:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-04-29 12:18:13,330:INFO:Calculating mean and std
2023-04-29 12:18:13,331:INFO:Creating metrics dataframe
2023-04-29 12:18:13,365:INFO:Uploading results into container
2023-04-29 12:18:13,365:INFO:Uploading model into container now
2023-04-29 12:18:13,365:INFO:_master_model_container: 11
2023-04-29 12:18:13,365:INFO:_display_container: 2
2023-04-29 12:18:13,366:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-04-29 12:18:13,366:INFO:create_model() successfully completed......................................
2023-04-29 12:18:13,420:INFO:SubProcess create_model() end ==================================
2023-04-29 12:18:13,420:INFO:Creating metrics dataframe
2023-04-29 12:18:13,423:INFO:Initializing Light Gradient Boosting Machine
2023-04-29 12:18:13,423:INFO:Total runtime is 5.052284495035806 minutes
2023-04-29 12:18:13,423:INFO:SubProcess create_model() called ==================================
2023-04-29 12:18:13,423:INFO:Initializing create_model()
2023-04-29 12:18:13,423:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458EE2460>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002140CEA98B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:18:13,423:INFO:Checking exceptions
2023-04-29 12:18:13,423:INFO:Importing libraries
2023-04-29 12:18:13,423:INFO:Copying training dataset
2023-04-29 12:18:13,502:INFO:Defining folds
2023-04-29 12:18:13,502:INFO:Declaring metric variables
2023-04-29 12:18:13,503:INFO:Importing untrained model
2023-04-29 12:18:13,503:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-29 12:18:13,503:INFO:Starting cross validation
2023-04-29 12:18:13,503:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-04-29 12:18:27,472:INFO:Calculating mean and std
2023-04-29 12:18:27,472:INFO:Creating metrics dataframe
2023-04-29 12:18:27,506:INFO:Uploading results into container
2023-04-29 12:18:27,506:INFO:Uploading model into container now
2023-04-29 12:18:27,506:INFO:_master_model_container: 12
2023-04-29 12:18:27,506:INFO:_display_container: 2
2023-04-29 12:18:27,507:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8245, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-29 12:18:27,507:INFO:create_model() successfully completed......................................
2023-04-29 12:18:27,564:INFO:SubProcess create_model() end ==================================
2023-04-29 12:18:27,564:INFO:Creating metrics dataframe
2023-04-29 12:18:27,567:INFO:Initializing CatBoost Classifier
2023-04-29 12:18:27,567:INFO:Total runtime is 5.28801321585973 minutes
2023-04-29 12:18:27,567:INFO:SubProcess create_model() called ==================================
2023-04-29 12:18:27,568:INFO:Initializing create_model()
2023-04-29 12:18:27,568:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458EE2460>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002140CEA98B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:18:27,568:INFO:Checking exceptions
2023-04-29 12:18:27,568:INFO:Importing libraries
2023-04-29 12:18:27,568:INFO:Copying training dataset
2023-04-29 12:18:27,648:INFO:Defining folds
2023-04-29 12:18:27,648:INFO:Declaring metric variables
2023-04-29 12:18:27,648:INFO:Importing untrained model
2023-04-29 12:18:27,648:INFO:CatBoost Classifier Imported successfully
2023-04-29 12:18:27,648:INFO:Starting cross validation
2023-04-29 12:18:27,649:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-04-29 12:19:03,271:INFO:Calculating mean and std
2023-04-29 12:19:03,271:INFO:Creating metrics dataframe
2023-04-29 12:19:03,310:INFO:Uploading results into container
2023-04-29 12:19:03,310:INFO:Uploading model into container now
2023-04-29 12:19:03,310:INFO:_master_model_container: 13
2023-04-29 12:19:03,310:INFO:_display_container: 2
2023-04-29 12:19:03,310:INFO:<catboost.core.CatBoostClassifier object at 0x00000214175B8FA0>
2023-04-29 12:19:03,310:INFO:create_model() successfully completed......................................
2023-04-29 12:19:03,366:INFO:SubProcess create_model() end ==================================
2023-04-29 12:19:03,366:INFO:Creating metrics dataframe
2023-04-29 12:19:03,370:INFO:Initializing Dummy Classifier
2023-04-29 12:19:03,370:INFO:Total runtime is 5.884719757239023 minutes
2023-04-29 12:19:03,370:INFO:SubProcess create_model() called ==================================
2023-04-29 12:19:03,370:INFO:Initializing create_model()
2023-04-29 12:19:03,370:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458EE2460>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002140CEA98B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:19:03,370:INFO:Checking exceptions
2023-04-29 12:19:03,370:INFO:Importing libraries
2023-04-29 12:19:03,370:INFO:Copying training dataset
2023-04-29 12:19:03,448:INFO:Defining folds
2023-04-29 12:19:03,448:INFO:Declaring metric variables
2023-04-29 12:19:03,448:INFO:Importing untrained model
2023-04-29 12:19:03,448:INFO:Dummy Classifier Imported successfully
2023-04-29 12:19:03,448:INFO:Starting cross validation
2023-04-29 12:19:03,449:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-04-29 12:19:14,814:INFO:Calculating mean and std
2023-04-29 12:19:14,814:INFO:Creating metrics dataframe
2023-04-29 12:19:14,850:INFO:Uploading results into container
2023-04-29 12:19:14,850:INFO:Uploading model into container now
2023-04-29 12:19:14,850:INFO:_master_model_container: 14
2023-04-29 12:19:14,850:INFO:_display_container: 2
2023-04-29 12:19:14,850:INFO:DummyClassifier(constant=None, random_state=8245, strategy='prior')
2023-04-29 12:19:14,850:INFO:create_model() successfully completed......................................
2023-04-29 12:19:14,905:INFO:SubProcess create_model() end ==================================
2023-04-29 12:19:14,905:INFO:Creating metrics dataframe
2023-04-29 12:19:14,908:INFO:Initializing create_model()
2023-04-29 12:19:14,908:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458EE2460>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:19:14,908:INFO:Checking exceptions
2023-04-29 12:19:14,908:INFO:Importing libraries
2023-04-29 12:19:14,908:INFO:Copying training dataset
2023-04-29 12:19:14,987:INFO:Defining folds
2023-04-29 12:19:14,988:INFO:Declaring metric variables
2023-04-29 12:19:14,988:INFO:Importing untrained model
2023-04-29 12:19:14,988:INFO:Declaring custom model
2023-04-29 12:19:14,988:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-29 12:19:14,988:INFO:Cross validation set to False
2023-04-29 12:19:14,988:INFO:Fitting Model
2023-04-29 12:19:16,821:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-29 12:19:16,821:INFO:create_model() successfully completed......................................
2023-04-29 12:19:16,879:INFO:Initializing create_model()
2023-04-29 12:19:16,879:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458EE2460>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8245, splitter='best'), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:19:16,879:INFO:Checking exceptions
2023-04-29 12:19:16,879:INFO:Importing libraries
2023-04-29 12:19:16,879:INFO:Copying training dataset
2023-04-29 12:19:16,962:INFO:Defining folds
2023-04-29 12:19:16,962:INFO:Declaring metric variables
2023-04-29 12:19:16,962:INFO:Importing untrained model
2023-04-29 12:19:16,962:INFO:Declaring custom model
2023-04-29 12:19:16,963:INFO:Decision Tree Classifier Imported successfully
2023-04-29 12:19:16,963:INFO:Cross validation set to False
2023-04-29 12:19:16,963:INFO:Fitting Model
2023-04-29 12:19:20,684:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8245, splitter='best')
2023-04-29 12:19:20,684:INFO:create_model() successfully completed......................................
2023-04-29 12:19:20,746:INFO:_master_model_container: 14
2023-04-29 12:19:20,746:INFO:_display_container: 2
2023-04-29 12:19:20,746:INFO:[QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8245, splitter='best')]
2023-04-29 12:19:20,746:INFO:compare_models() successfully completed......................................
2023-04-29 12:19:20,746:INFO:Initializing tune_model()
2023-04-29 12:19:20,746:INFO:tune_model(estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=log_loss, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458EE2460>)
2023-04-29 12:19:20,746:INFO:Checking exceptions
2023-04-29 12:19:20,780:INFO:Copying training dataset
2023-04-29 12:19:20,833:INFO:Checking base model
2023-04-29 12:19:20,834:INFO:Base model : Quadratic Discriminant Analysis
2023-04-29 12:19:20,834:INFO:Declaring metric variables
2023-04-29 12:19:20,834:INFO:Defining Hyperparameters
2023-04-29 12:19:20,887:INFO:Tuning with n_jobs=-1
2023-04-29 12:19:20,887:INFO:Initializing RandomizedSearchCV
2023-04-29 12:19:25,423:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:25,833:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:25,976:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:26,137:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:26,360:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:26,531:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:27,099:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:27,424:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:27,744:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:28,020:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:28,113:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:28,348:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:28,656:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:29,016:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:29,197:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:29,510:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:30,211:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:30,562:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:30,963:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:31,222:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:31,578:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:31,905:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:32,118:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:32,572:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:32,945:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:33,191:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:33,707:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:33,842:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:34,142:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:34,482:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:34,906:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:35,098:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:35,474:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:35,814:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:36,063:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:36,395:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:36,780:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:36,847:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:37,495:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:37,598:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:37,873:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:38,493:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:38,773:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:38,886:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:39,133:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:39,596:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:39,812:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:40,203:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:40,615:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:41,011:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:41,401:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:41,511:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:41,917:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:42,212:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:42,618:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:43,124:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:43,195:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:43,489:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:43,950:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:44,401:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:44,563:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:45,056:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:45,414:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:45,801:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:45,815:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:46,289:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:46,701:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:46,786:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:47,135:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:47,479:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:48,042:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:48,446:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:48,613:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:48,970:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:49,332:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:49,520:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:49,862:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:50,562:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:50,642:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:50,963:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:51,121:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:51,560:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:51,924:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:52,288:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:52,645:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:52,952:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:53,190:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:53,836:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:53,907:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:54,303:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:54,874:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:54,959:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:55,312:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:55,710:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:55,856:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:55,967:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:56,146:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:56,312:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:56,535:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:56,701:WARNING:C:\Users\Administrator\anaconda3\envs\tf274gpu\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-29 12:19:57,081:INFO:best_params: {'actual_estimator__reg_param': 0.2}
2023-04-29 12:19:57,081:INFO:Hyperparameter search completed
2023-04-29 12:19:57,081:INFO:SubProcess create_model() called ==================================
2023-04-29 12:19:57,081:INFO:Initializing create_model()
2023-04-29 12:19:57,081:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458EE2460>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214190BDC70>, model_only=True, return_train_score=False, kwargs={'reg_param': 0.2})
2023-04-29 12:19:57,081:INFO:Checking exceptions
2023-04-29 12:19:57,081:INFO:Importing libraries
2023-04-29 12:19:57,081:INFO:Copying training dataset
2023-04-29 12:19:57,172:INFO:Defining folds
2023-04-29 12:19:57,172:INFO:Declaring metric variables
2023-04-29 12:19:57,173:INFO:Importing untrained model
2023-04-29 12:19:57,173:INFO:Declaring custom model
2023-04-29 12:19:57,173:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-29 12:19:57,173:INFO:Starting cross validation
2023-04-29 12:19:57,173:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-04-29 12:20:17,998:INFO:Calculating mean and std
2023-04-29 12:20:17,999:INFO:Creating metrics dataframe
2023-04-29 12:20:18,000:INFO:Finalizing model
2023-04-29 12:20:19,841:INFO:Uploading results into container
2023-04-29 12:20:19,841:INFO:Uploading model into container now
2023-04-29 12:20:19,842:INFO:_master_model_container: 15
2023-04-29 12:20:19,842:INFO:_display_container: 3
2023-04-29 12:20:19,842:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.2,
                              store_covariance=False, tol=0.0001)
2023-04-29 12:20:19,842:INFO:create_model() successfully completed......................................
2023-04-29 12:20:19,895:INFO:SubProcess create_model() end ==================================
2023-04-29 12:20:19,895:INFO:choose_better activated
2023-04-29 12:20:19,895:INFO:SubProcess create_model() called ==================================
2023-04-29 12:20:19,897:INFO:Initializing create_model()
2023-04-29 12:20:19,897:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458EE2460>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:20:19,897:INFO:Checking exceptions
2023-04-29 12:20:19,897:INFO:Importing libraries
2023-04-29 12:20:19,897:INFO:Copying training dataset
2023-04-29 12:20:19,975:INFO:Defining folds
2023-04-29 12:20:19,975:INFO:Declaring metric variables
2023-04-29 12:20:19,975:INFO:Importing untrained model
2023-04-29 12:20:19,975:INFO:Declaring custom model
2023-04-29 12:20:19,975:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-29 12:20:19,975:INFO:Starting cross validation
2023-04-29 12:20:19,977:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-04-29 12:20:41,198:INFO:Calculating mean and std
2023-04-29 12:20:41,198:INFO:Creating metrics dataframe
2023-04-29 12:20:41,199:INFO:Finalizing model
2023-04-29 12:20:43,041:INFO:Uploading results into container
2023-04-29 12:20:43,041:INFO:Uploading model into container now
2023-04-29 12:20:43,041:INFO:_master_model_container: 16
2023-04-29 12:20:43,041:INFO:_display_container: 4
2023-04-29 12:20:43,041:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-29 12:20:43,041:INFO:create_model() successfully completed......................................
2023-04-29 12:20:43,098:INFO:SubProcess create_model() end ==================================
2023-04-29 12:20:43,098:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) result for Log_loss is 9.094
2023-04-29 12:20:43,098:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.2,
                              store_covariance=False, tol=0.0001) result for Log_loss is 0.4569
2023-04-29 12:20:43,098:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) is best model
2023-04-29 12:20:43,098:INFO:choose_better completed
2023-04-29 12:20:43,099:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-29 12:20:43,105:INFO:_master_model_container: 16
2023-04-29 12:20:43,105:INFO:_display_container: 3
2023-04-29 12:20:43,105:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-29 12:20:43,105:INFO:tune_model() successfully completed......................................
2023-04-29 12:20:43,196:INFO:Initializing tune_model()
2023-04-29 12:20:43,196:INFO:tune_model(estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8245, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=log_loss, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458EE2460>)
2023-04-29 12:20:43,197:INFO:Checking exceptions
2023-04-29 12:20:43,229:INFO:Copying training dataset
2023-04-29 12:20:43,282:INFO:Checking base model
2023-04-29 12:20:43,282:INFO:Base model : Decision Tree Classifier
2023-04-29 12:20:43,283:INFO:Declaring metric variables
2023-04-29 12:20:43,283:INFO:Defining Hyperparameters
2023-04-29 12:20:43,334:INFO:Tuning with n_jobs=-1
2023-04-29 12:20:43,334:INFO:Initializing RandomizedSearchCV
2023-04-29 12:21:15,970:INFO:best_params: {'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.2, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 7, 'actual_estimator__criterion': 'gini'}
2023-04-29 12:21:15,970:INFO:Hyperparameter search completed
2023-04-29 12:21:15,970:INFO:SubProcess create_model() called ==================================
2023-04-29 12:21:15,970:INFO:Initializing create_model()
2023-04-29 12:21:15,970:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458EE2460>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8245, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021413FE8160>, model_only=True, return_train_score=False, kwargs={'min_samples_split': 10, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.2, 'max_features': 'log2', 'max_depth': 7, 'criterion': 'gini'})
2023-04-29 12:21:15,970:INFO:Checking exceptions
2023-04-29 12:21:15,970:INFO:Importing libraries
2023-04-29 12:21:15,970:INFO:Copying training dataset
2023-04-29 12:21:16,061:INFO:Defining folds
2023-04-29 12:21:16,061:INFO:Declaring metric variables
2023-04-29 12:21:16,061:INFO:Importing untrained model
2023-04-29 12:21:16,061:INFO:Declaring custom model
2023-04-29 12:21:16,061:INFO:Decision Tree Classifier Imported successfully
2023-04-29 12:21:16,061:INFO:Starting cross validation
2023-04-29 12:21:16,062:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-04-29 12:21:37,150:INFO:Calculating mean and std
2023-04-29 12:21:37,150:INFO:Creating metrics dataframe
2023-04-29 12:21:37,150:INFO:Finalizing model
2023-04-29 12:21:38,973:INFO:Uploading results into container
2023-04-29 12:21:38,974:INFO:Uploading model into container now
2023-04-29 12:21:38,974:INFO:_master_model_container: 17
2023-04-29 12:21:38,974:INFO:_display_container: 4
2023-04-29 12:21:38,974:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=7, max_features='log2', max_leaf_nodes=None,
                       min_impurity_decrease=0.2, min_samples_leaf=5,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       random_state=8245, splitter='best')
2023-04-29 12:21:38,974:INFO:create_model() successfully completed......................................
2023-04-29 12:21:39,030:INFO:SubProcess create_model() end ==================================
2023-04-29 12:21:39,030:INFO:choose_better activated
2023-04-29 12:21:39,030:INFO:SubProcess create_model() called ==================================
2023-04-29 12:21:39,030:INFO:Initializing create_model()
2023-04-29 12:21:39,030:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458EE2460>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8245, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:21:39,030:INFO:Checking exceptions
2023-04-29 12:21:39,031:INFO:Importing libraries
2023-04-29 12:21:39,031:INFO:Copying training dataset
2023-04-29 12:21:39,110:INFO:Defining folds
2023-04-29 12:21:39,110:INFO:Declaring metric variables
2023-04-29 12:21:39,110:INFO:Importing untrained model
2023-04-29 12:21:39,110:INFO:Declaring custom model
2023-04-29 12:21:39,110:INFO:Decision Tree Classifier Imported successfully
2023-04-29 12:21:39,110:INFO:Starting cross validation
2023-04-29 12:21:39,111:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-04-29 12:22:17,833:INFO:Calculating mean and std
2023-04-29 12:22:17,833:INFO:Creating metrics dataframe
2023-04-29 12:22:17,834:INFO:Finalizing model
2023-04-29 12:22:19,638:INFO:Uploading results into container
2023-04-29 12:22:19,638:INFO:Uploading model into container now
2023-04-29 12:22:19,639:INFO:_master_model_container: 18
2023-04-29 12:22:19,639:INFO:_display_container: 5
2023-04-29 12:22:19,639:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8245, splitter='best')
2023-04-29 12:22:19,639:INFO:create_model() successfully completed......................................
2023-04-29 12:22:19,693:INFO:SubProcess create_model() end ==================================
2023-04-29 12:22:19,694:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8245, splitter='best') result for Log_loss is 10.3868
2023-04-29 12:22:19,694:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=7, max_features='log2', max_leaf_nodes=None,
                       min_impurity_decrease=0.2, min_samples_leaf=5,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       random_state=8245, splitter='best') result for Log_loss is 0.466
2023-04-29 12:22:19,694:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8245, splitter='best') is best model
2023-04-29 12:22:19,694:INFO:choose_better completed
2023-04-29 12:22:19,694:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-29 12:22:19,701:INFO:_master_model_container: 18
2023-04-29 12:22:19,701:INFO:_display_container: 4
2023-04-29 12:22:19,701:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8245, splitter='best')
2023-04-29 12:22:19,701:INFO:tune_model() successfully completed......................................
2023-04-29 12:22:19,796:INFO:Initializing blend_models()
2023-04-29 12:22:19,796:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458EE2460>, estimator_list=[QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8245, splitter='best')], fold=5, round=4, choose_better=False, optimize=log_loss, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-04-29 12:22:19,796:INFO:Checking exceptions
2023-04-29 12:22:19,832:INFO:Importing libraries
2023-04-29 12:22:19,832:INFO:Copying training dataset
2023-04-29 12:22:19,832:INFO:Getting model names
2023-04-29 12:22:19,832:INFO:SubProcess create_model() called ==================================
2023-04-29 12:22:19,833:INFO:Initializing create_model()
2023-04-29 12:22:19,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458EE2460>, estimator=VotingClassifier(estimators=[('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Decision Tree Classifier',
                              DecisionTreeClassifier(ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features=None,
                                                     max_leaf_nodes=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     random_state=8245,
                                                     splitter='best'))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='soft',
                 weights=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002141825C550>, model_only=True, return_train_score=False, kwargs={})
2023-04-29 12:22:19,833:INFO:Checking exceptions
2023-04-29 12:22:19,833:INFO:Importing libraries
2023-04-29 12:22:19,833:INFO:Copying training dataset
2023-04-29 12:22:19,908:INFO:Defining folds
2023-04-29 12:22:19,908:INFO:Declaring metric variables
2023-04-29 12:22:19,908:INFO:Importing untrained model
2023-04-29 12:22:19,908:INFO:Declaring custom model
2023-04-29 12:22:19,908:INFO:Voting Classifier Imported successfully
2023-04-29 12:22:19,908:INFO:Starting cross validation
2023-04-29 12:22:19,909:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-04-29 12:22:39,781:INFO:Calculating mean and std
2023-04-29 12:22:39,781:INFO:Creating metrics dataframe
2023-04-29 12:22:39,782:INFO:Finalizing model
2023-04-29 12:22:43,616:INFO:Uploading results into container
2023-04-29 12:22:43,617:INFO:Uploading model into container now
2023-04-29 12:22:43,617:INFO:_master_model_container: 19
2023-04-29 12:22:43,617:INFO:_display_container: 5
2023-04-29 12:22:43,618:INFO:VotingClassifier(estimators=[('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Decision Tree Classifier',
                              DecisionTreeClassifier(ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features=None,
                                                     max_leaf_nodes=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     random_state=8245,
                                                     splitter='best'))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='soft',
                 weights=None)
2023-04-29 12:22:43,618:INFO:create_model() successfully completed......................................
2023-04-29 12:22:43,676:INFO:SubProcess create_model() end ==================================
2023-04-29 12:22:43,681:INFO:_master_model_container: 19
2023-04-29 12:22:43,681:INFO:_display_container: 5
2023-04-29 12:22:43,682:INFO:VotingClassifier(estimators=[('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Decision Tree Classifier',
                              DecisionTreeClassifier(ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features=None,
                                                     max_leaf_nodes=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     random_state=8245,
                                                     splitter='best'))],
                 flatten_transform=True, n_jobs=1, verbose=False, voting='soft',
                 weights=None)
2023-04-29 12:22:43,682:INFO:blend_models() successfully completed......................................
2023-04-29 12:22:43,718:INFO:Initializing get_config()
2023-04-29 12:22:43,719:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458EE2460>, variable=prep_pipe)
