분류문제에서 딥러닝은 layer를 거쳐 선을 수정하지만, 머신러닝은 단층 레이어로 선을 그어 클래스를 분류한다.
때문에 고도화된 문제는 완벽한 분류를 위해 개발자가 파라미터 조정을 해야한다.
or, and, xor 문제 에서
or, and는 하나의 선으로 해결 가능하지만,
xor 문제는 하나의 선으로 해결 불가능.
때문에 단층 퍼셉트론을 사용하던 기존과 달리 다층 퍼셉트론이 등장하기 시작
###############################################################


###############################################################
all_estimators
from sklearn.utils import all_estimators
모든 모델에 대한 평가
allAlgorithms = all_estimators(type_filter='regressor')
allAlgorithms = all_estimators(type_filter='classifier')
max_r2 = 0
max_name = '바보'
for (name, algorithm) in allAlgorithms:
    try: #에러 예외처리
        model = algorithm()
        #3. 훈련
        model.fit(x_train, y_train)
        
        #4. 평가, 예측
        results = model.score(x_test, y_test)
        print(name,'의 정답률 :', results)
        if max_r2 < results :
            max_r2 = results
            max_name = name
        # y_predict = model.predict(x_test)
        # # print(y_test.dtype)  #데이터 타입 확인
        # # print(y_predict.dtype) #데이터 타입 확인    데이터 타입 변경은 astype 사용함.
        # r2 = r2_score(y_test, y_predict)
        # print('r2_score :', r2)
    except:
        #에러가 뜨면 except로 바로 넘어간다. 에러가 안뜨면 정상적으로 for문이 돌아감.
        print(name, '은(는) 에러뜬 놈!!!')
        #에러가 뜨는 모델들은 기본적으로 파라미터 수정이 필요한 모델들이다.
print('===================================')
print('최고모델 :', max_name, max_r2)
print('===================================')
###############################################################




###############################################################
k폴드
from sklearn.model_selection import KFold, cross_val_score
kfold = KFold(n_splits = n_splits, shuffle=True, random_state=123)
for i, datasets in enumerate(datasets):
    x,y = datasets
    print(f"\n데이터셋 {i+1}:")
    scores = cross_val_score(model, x, y, cv=kfold, n_jobs=-1)   # n_jobs= 사용할 코어 갯수
    print('ACC :', scores, '\ncross_val_score 평균 : ', round(np.mean(scores), 4))

kfold = KFold() 디폴트가 5. 데이터를 훈련시키는 위치에 따라서 성능차이 엄청남
기존에는 test 데이터를, train데이터와 다른 데이터로 구분함으로써 평가 용도로 사용하였는데 이를 구분없이 사용하면 이 또한 과적합이라 볼 수 있다.
따라서 테스트 데이터를 분리한 후, cross_val 시켜주는 방법도 있다.

일반적인 kfold의 문제점
문제점 1. train, test/ test로 predict 한 것이므로 과적합만큼 결과의 acc가 안나올 수 있음
문제점 2. stratify kfold 과정중에 y값이 편향될 수 있다.
StratifiedKFold = 비율대로 잘라주는 kfold. 위 문제점을 해결할 수 있다.
분류 문제에서만 사용함.
###############################################################


###############################################################
from sklearn.model_selection import KFold, cross_val_score, GridSearchCV, StratifiedKFold 

GridSearch
파라미터 전체 조사
대부분의 파라미터는 모델과 fit에서 정의함
gridSearch는 모든 파라미터를 돌려본다

gridsearch 포문 구현
for i in gamma:
    for j in C:
        #2. 모델
        model = SVC(gamma=i, C=j)
        
        #3. 컴파일, 훈련
        model.fit(x_train, y_train)
        
        #4. 평가, 예측
        #텐서플로의 evaluate
        #사이킷런의 score
        score = model.score(x_test, y_test)
                
        if max_score < score :
            max_score = score
            best_parameters = {'gamma' : i, 'C' : j} # if문은 if문끼리 묶여있다. 점수가 갱신될때만 best_parameters도 갱신된다.
gridSearch는 crossval 기능도 있다


랜덤서치
from sklearn.model_selection import RandomizedSearchCV
RandomSearch는 fold 하나당 x개씩만 랜덤하게 뽑아서 훈련

할빙그리드서치 
정해진 알고리즘대로 뽑아서 훈련함
from sklearn.model_selection import HalvingGridSearchCV

###############################################################

from sklearn.pipeline import make_pipeline

전처리와 모델을 한번에 사용하는 법
model = make_pipeline(StandardScaler(), SVC())

for i in range(len(data_list)):
    x, y = data_list[i](return_X_y=True)
    x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state= 337, stratify=y)
    max_score = 0
    
    for j, value2 in enumerate(scaler_list):
        
        for k, value3 in enumerate(model_list):
            
            model = make_pipeline(value2, value3)
            model.fit(x_train, y_train)
            score = model.score(x_test, y_test)
            y_pred=model.predict(x_test)
            acc=accuracy_score(y_test, y_pred)
            
            if max_score < score:
                max_score = score
                max_s_name = scaler_name[j]
                max_model_name = model_name_list[k]

포문에 넣을수도 있음

PCA사용 예
model = make_pipeline(PCA(n_components=8),StandardScaler(), SVC())

일반 파이프라인
from sklearn.pipeline import Pipeline
model = Pipeline([("std",StandardScaler()), ('svc',SVC())])   
파이프라인은 리스트 형태로 입력해야함
파이프라인은 튜플 형식, 이름 지정까지 함께 입력해야한다.

3중 포문 파이프라인
for i in range(len(data_list)):
    x, y = data_list[i](return_X_y=True)
    x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state= 337, stratify=y)
    max_score = 0
    
    for j, value2 in enumerate(scaler_list):
        
        for k, value3 in enumerate(model_list):
            
            model = Pipeline([('scaler',value2), ('model',value3)])
            model.fit(x_train, y_train)
            score = model.score(x_test, y_test)
            y_pred=model.predict(x_test)
            acc=accuracy_score(y_test, y_pred)
            
            if max_score < score:
                max_score = score
                max_s_name = scaler_name[j]
                max_model_name = model_name_list[k]

파이프라인 그리드서치
pipe = Pipeline([("std",StandardScaler()), ('rf',RandomForestClassifier())])
model = GridSearchCV(pipe, parameters,
                     cv = 5,
                     verbose=1,
                     n_jobs=-1
                     )
###############################################################


피쳐 임포턴스
feature_importances_
컬런의 종류에 따라 훈련 결과에 악영향을 끼치는 불필요한 컬런이 있다.
때문에 컬런을 걸러내는 작업을 함.
ex)PCA
for i,v in enumerate(models):
    model = v
    model.fit(x_train, y_train)
    result = model.score(x_test,y_test)
    y_predict = model.predict(x_test)
    acc = accuracy_score(y_test, y_predict)
    print(model_name[i], ':', "acc", acc)
    if i !=3:
        print(model, ':', '컬럼별 중요도',model.feature_importances_)
    else :
        print('XGBClassifier()', model.feature_importances_)
    print('----------------------------------------------')


