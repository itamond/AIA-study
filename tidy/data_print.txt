import numpy as np
import pandas as pd

#pd->np 변경
data.to_numpy()
data.values

#np->pd 변경
pd.DataFrame()

#list->numpy 변경

#list->pandas 변경

# dtype 변경
train_data.iloc[:,2:] = train_data.iloc[:,2:].astype(float)
=================================================================
###결측치제거### 
print(data.isnull().sum())

##data_drop
train_data = train_data.drop(['motor_current'], axis=1)
test_data = test_data.drop(['motor_current'], axis=1)

##
# print(model.cv_results_) : 한 눈에 보기 어려움 
# pd : 컬럼 하나(1차원)-Seris,벡터 / list형태 - DataFrame
print(pd.DataFrame(model.cv_results_).sort_values('rank_test_score', ascending=True)) #값순으로 정렬 : sort_values,ascending=True(오름차순:디폴트)/ false:(내림차순)
#[48 rows x 17 columns] : 48개 훈련에 대해서 17가지 결과값으로 보여줌
print(pd.DataFrame(model.cv_results_).columns) #pd컬럼명 확인
print(datasets.feature_names)                  #sklearn컬럼명확인

##pd
print(data.value_counts()) #컬럼별 개수확인 
print(data.value_counts().sort_index()) #컬럼별 개수확인 , idex 오름차순
##np
print(np.unique(y, return_counts=True))  #컬럼별 개수확인
data.unique()#컬럼목록 확인
##
movies[movies['year'].isnull()] #결측값 확인
movies['year'] = movies['year'].fillna('2050') #결측값 처리


# data 합치기 
x = np.concatenate((x_train,x_test), axis=0)  #(70000, 28, 28)
x = np.append(x_train, x_test, axis=0)      #(70000, 28, 28)

#데이터확인 
# print(train_csv.columns)
# print(train_csv.info())
# print(train_csv.describe())
# print(train_csv.describe())



####################################################################
#ml 
#1.피클 저장 
import pickle
path = './_save/pickle_test/'
pickle.dump(model, open(path + 'm43_pickle1_save.dat', 'wb'))

#2.피클 불러오기 
import pickle
path = './_save/pickle_test/'
model = pickle.load(open(path + 'm43_pickle1_save.dat', 'rb'))
####################################################################
#1.피클 저장 
import joblib
path = './_save/pickle_test/'
joblib.dump(model, path + 'm44_joblib1_save.dat')

#2. 모델 - 잡립 불러오기 
import joblib
path = './_save/pickle_test/'
model = joblib.load(path + 'm43_pickle1_save.dat')
####################################################################